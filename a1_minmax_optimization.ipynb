{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akimotolab/CMAES_Tutorial/blob/main/a1_minmax_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evolution Strategyによるミニマックス最適化\n",
        "\n",
        "ここではESを用いたミニマックス最適化について紹介する．\n",
        "特に，\n",
        "1. 局所探索を志向した方法である Adversarial-CMA-ES [1] （pythonコード： https://gist.github.com/youheiakimoto/ab51e88c73baf68effd95b750100aad0#comments）\n",
        "\n",
        "2. 大域探索＆並列化を志向した方法である WRA-CMA-ES [2] (pythonコード： https://github.com/akimotolab/worstcase-ranking-approximation)\n",
        "\n",
        "を紹介する．\n",
        "\n",
        "[1] Youhei Akimoto, Yoshiki Miyauchi, and Atsuo Maki. 2022.\n",
        "Saddle Point Optimization with Approximate Minimization Oracle and Its Application to Robust Berthing Control.\n",
        "ACM Trans. Evol. Learn. Optim. 2, 1, Article 2 (March 2022), 32 pages.\n",
        "DOI:https://doi.org/10.1145/3510425\n",
        "\n",
        "[2] Atsuhiro Miyagi, Yoshiki Miyauchi, Atsuo Maki, Kazuto Fukuchi, Jun Sakuma, and Youhei Akimoto. 2023. Covariance Matrix Adaptation Evolutionary Strategy with Worst-Case Ranking Approximation for Min-Max Optimization and Its Application to Berthing Control Tasks. ACM Trans. Evol. Learn. Optim. 3, 2, Article 8 (June 2023), 32 pages. https://doi.org/10.1145/3603716"
      ],
      "metadata": {
        "id": "wjsSYIpuxs8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 背景\n",
        "\n",
        "ESが活用される場面では，多くの場合，目的関数$f$は与えられた入力$x$に対する数値シミュレーションを介して計算される．\n",
        "当然，シミュレーションによって計算される目的関数値が，現実世界に実装した場合の解$x$の良さを表していることを期待するが，現実的にはそうならない場合が多く見られる．\n",
        "例えば，タイヤの形状を最適化するような場面を考える．どのような指標を良さに表すのかについては議論しないが，タイヤの形状の良し悪しを評価するためにシミュレーションを実施すると言っても，路面の状態や気象状況によってシミュレーションの結果が変わることは容易に想像される．\n",
        "ここでいう，路面の状態や気象状況などの，シミュレーション実施時には知り得ない（運用時の天候はシミュレーション実施時にはわからない），もしくはそもそも一意に定まらない（天候も路面状態も運用する時々で変化する）ような要因を不確実性などと呼ぶ．\n",
        "これを$y$で表すことにする．\n",
        "この$y$は，シミュレーションの条件設定を表していると考えることもできる．\n",
        "一般的な最適化の場合，最適化実施前に$y$を予め決めておき，\n",
        "$$\n",
        "x^* = \\mathrm{argmax}_x f(x, y)\n",
        "$$\n",
        "となるような解$x^*$を求めようとしている，と考えられる．\n",
        "しかし，最適化実施時に設定した$y_\\mathrm{sim}$と運用時に直面する$y$が異なることで，目的関数値が著しく悪化する，すなわち$f(x^*, y_\\mathrm{sim}) \\ll f(x^*, y)$となる可能性がある．"
      ],
      "metadata": {
        "id": "iuKxmmlr5_Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### テスト問題での例\n",
        "具体的なテスト問題２つでこの現象を確認する．\n",
        "\n",
        "#### 凹凸二次関数\n",
        "１つ目の問題は凹凸二次関数\n",
        "$$\n",
        "f(x, y) = a x^2 + b x y - c y^2\n",
        "$$\n",
        "である．\n",
        "簡単のため，定義域は$\\mathbb{R} \\times \\mathbb{R}$とする．\n",
        "係数については，$a, c > 0$，$b \\in \\mathbb{R}$とする．\n",
        "各$y$について，最適な$x$は\n",
        "$$\n",
        "x^*(y) = \\frac{-by}{2a}\n",
        "$$\n",
        "であることから，最適な$x$が$y$に依存することがわかる．\n",
        "とりわけ，$| b | / a$が大きいほど，$y$の変化に対して最適解が大きく変化することがわかる．\n",
        "各$y$について，最適解をとった場合の目的関数値は\n",
        "$$\n",
        "f(x^*(y), y) = - \\left( \\frac{b^2}{4a} + c\\right) y^2\n",
        "$$\n",
        "となる．\n",
        "しかし，最適化時に用いた$y_\\mathrm{sim}$と運用時の$y$が異なれば，\n",
        "$$\n",
        "f(x^*(y_\\mathrm{sim}), y) = \\frac{b^2}{4 a} \\left( y_\\mathrm{sim} - y\\right)^2 - \\left(\\frac{b^2}{4 a} + c\\right) y^2\n",
        "$$\n",
        "となる．\n",
        "すなわち，第一項の分だけ，本来の最適な値よりも損をすることになる．\n",
        "第一項はシミュレーションに用いた$y_\\mathrm{sim}$と運用時の$y$が離れているほどに大きくなることも見て取れる．\n",
        "\n",
        "#### 双線形関数\n",
        "２つ目の問題は双線形関数\n",
        "$$\n",
        "f(x, y) = x y\n",
        "$$\n",
        "である．\n",
        "定義域は$[-1, 1]\\times [-1, 1]$とする．\n",
        "各$y$について最適な解は\n",
        "$$\n",
        "x^*(y) = -\\mathrm{sign}(y)\n",
        "$$\n",
        "となる．\n",
        "$y=0$の場合には，任意の$x$が最適となるが，簡単のため$x^* = 0$と考えることにする．\n",
        "この問題の場合，最適解が不連続に変化することになる．\n",
        "各$y$について，最適解をとった場合の目的関数値は\n",
        "$$\n",
        "f(x^*(y), y) = - |y|\n",
        "$$\n",
        "となる．\n",
        "他方，最適化時に用いた$y_\\mathrm{sim}$と運用時の$y$が異なれば，\n",
        "$$\n",
        "f(x^*(y_\\mathrm{sim}), y) = - \\mathrm{sign}(y_\\mathrm{sim}) y\n",
        "$$\n",
        "となる．\n",
        "最適化時に用いた$y_\\mathrm{sim}$と運用時の$y$の符号が一致している限り，最適化で得られた解が運用時にも最適な解となるが，符号が一致していない場合には性能劣化が起こることが見て取れる．"
      ],
      "metadata": {
        "id": "xSkLwxcT6DCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ミニマックス最適化問題\n",
        "不確実性を含む問題においては，様々なアプローチが考えられるが，ここでは「考えうる最悪なシナリオでの性能を最適化する解を求める問題」を考える．\n",
        "運用時に起こり得る不確実性の集合$Y$を予め特定できると考える．\n",
        "ある解$x$が与えられたもとで，この$x$にとって最悪性能を与える$y \\in Y$を考える．\n",
        "この最悪性能を表す指標を\n",
        "$$\n",
        "F_Y(x) = \\max_{y \\in Y} f(x, y)\n",
        "$$\n",
        "と書けば，この最悪性能$F_Y$を最小化するような解を見つけることがここでの目的であり，これはミニマックス最適化\n",
        "$$\n",
        "x^* = \\mathrm{argmax}_x F_Y(x) = \\mathrm{argmax}_x \\max_{y \\in Y} f(x, y)\n",
        "$$\n",
        "として定式化される．\n",
        "ESが対象とするような最適化問題において，目的関数はブラックボックスであるため，最悪性能$F_Y(x)$を解析的に求めることはできない．そのため，$F_Y(x)$を求めるために，各$x$に対して最悪なシナリオを求める必要がある．実用上は$Y$を適切に定めることも困難さの一つといえるが，この資料ではその後の最適化のみに着目する．"
      ],
      "metadata": {
        "id": "KJ7rkREENRVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ナイーブなアプローチ：有限サンプルを用いた最悪ケースの近似\n",
        "\n",
        "最も単純な方法としては，$Y$上の事前分布から予め$M$個の値$y_1, \\dots, y_M$をサンプリングしておき，もしくは最悪シナリオの後を予め予測できる場合には用意しておき，最悪性能を\n",
        "$$\n",
        "\\tilde{F}_Y(x) = \\max_{m=1, \\dots, M} f(x, y_m)\n",
        "$$\n",
        "で近似する方法が考えられる．\n",
        "この場合，一度の$\\tilde{F}_Y(x)$の計算に$M$回のシミュレーション（$f(x, y_m)$の計算）が必要になるが，並列評価可能であれば，一度のシミュレーション時間で$\\tilde{F}_Y$を計算することが可能であり，また，通常の進化戦略を用いて最適化することができる．\n",
        "この方法で実用に耐えうる解が得られる場合もあるが，一般に，サンプリングされたシナリオから離れたシナリオに対しては性能の低い解が得られる．"
      ],
      "metadata": {
        "id": "wBB7KEV0IwWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### テスト問題での実行例\n",
        "\n",
        "凹凸二次関数を用いた場合の近似最悪性能と真の最悪性能の差を確認する．"
      ],
      "metadata": {
        "id": "t9H_uENaK_2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 簡単のため， x と y の次元数は等しいとする．\n",
        "N = 1\n",
        "a = c = 1.0\n",
        "b = 10.0\n",
        "\n",
        "def f(x, y):\n",
        "    return a * np.dot(x, x) + b * np.dot(x, y) - c * np.dot(y, y)\n",
        "\n",
        "def f_worst(x):\n",
        "    y = b * x / 2 / c\n",
        "    return f(x, y)\n",
        "\n",
        "# シナリオサンプル．ここでは標準正規分布からサンプリング\n",
        "M = 10\n",
        "y_array = np.random.randn(M, N)\n",
        "def f_worst_approx(x):\n",
        "    return max([f(x, y) for y in y_array])"
      ],
      "metadata": {
        "id": "89dcgYrTG5qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_array = np.linspace(-1, 1, 100)\n",
        "f_worst_array = np.array([f_worst(x) for x in x_array])\n",
        "f_worst_approx_array = np.array([f_worst_approx(x) for x in x_array])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_array, f_worst_array, label=r'$F_Y$')\n",
        "plt.plot(x_array, f_worst_approx_array, label=r'$\\tilde{F}_Y$')\n",
        "plt.legend()\n",
        "\n",
        "x_array = np.linspace(-0.1, 0.1, 100)\n",
        "f_worst_array = np.array([f_worst(x) for x in x_array])\n",
        "f_worst_approx_array = np.array([f_worst_approx(x) for x in x_array])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_array, f_worst_array, label=r'$F_Y$')\n",
        "plt.plot(x_array, f_worst_approx_array, label=r'$\\tilde{F}_Y$')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Fx58oyKFMAfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "近似最悪性能$\\tilde{F}_Y(x)$は必ず真の最悪性能$F_Y(x)$以下の値となる．大域的にみると，$F_Y$の最適解近傍での関数値が$\\tilde{F}_{Y}$によってよく近似されているように見える（乱数による）が，最適解近傍を拡大すると，$\\tilde{F}_Y$の最適解は$F_Y$の最適解$x^* = 0$から離れていることがわかる．"
      ],
      "metadata": {
        "id": "XEcJEg3CSG92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CMA-ESで最適化\n",
        "DD-CMA-ESを用いて最適化してみる．"
      ],
      "metadata": {
        "id": "zRDPoNsvUFaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DD-CMA-ES　（実行後，非表示推奨）\n",
        "以下のコードはgistからのコピー: https://gist.github.com/youheiakimoto/1180b67b5a0b1265c204cba991fa8518"
      ],
      "metadata": {
        "id": "c6_feyHIVF2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from collections import deque\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DdCma:\n",
        "    \"\"\"dd-CMA: CMA-ES with diagonal decoding [1]\n",
        "    Note\n",
        "    ----\n",
        "    If you are interested in constrained optimization and/or multi-fidelity optimization,\n",
        "    check the following repository:\n",
        "    https://github.com/akimotolab/multi-fidelity\n",
        "\n",
        "    History\n",
        "    -------\n",
        "    2022/03/24: Mirroring box constraint handling and periodic variable handling [3] have been implemented.\n",
        "    2020/06/10: Restart (IPOP mechanism) [2] has been implemented.\n",
        "    2019/03/23: release\n",
        "    Reference\n",
        "    ---------\n",
        "    [1] Y. Akimoto and N. Hansen.\n",
        "    Diagonal Acceleration for Covariance Matrix Adaptation Evolution Strategies\n",
        "    Evolutionary Computation (2020) 28(3): 405--435.\n",
        "    [2] A. Auger and N. Hansen.\n",
        "    A Restart CMA Evolution Strategy With Increasing Population Size\n",
        "    IEEE Congress on Evolutionary Computation (2005): 1769-1776.\n",
        "    [3] Y. Yamaguchi and A. Akimoto.\n",
        "    A Note on the CMA-ES for Functions with Periodic Variables\n",
        "    Genetic and Evolutionary Computation Conference Companion (2018): 227-228.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, xmean0, sigma0,\n",
        "                 lam=None,\n",
        "                 flg_covariance_update=True,\n",
        "                 flg_variance_update=True,\n",
        "                 flg_active_update=True,\n",
        "                 flg_force_correlation=None,\n",
        "                 beta_eig=None,\n",
        "                 beta_thresh=2.):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        xmean0 : 1d array-like\n",
        "            initial mean vector\n",
        "        sigma0 : 1d array-like\n",
        "            initial diagonal decoding\n",
        "        lam : int, optional (default = None)\n",
        "            population size\n",
        "        flg_covariance_update : bool, optional (default = True)\n",
        "            update C if this is True\n",
        "        flg_variance_update : bool, optional (default = True)\n",
        "            update D if this is True\n",
        "        flg_active_update : bool, optional (default = True)\n",
        "            update C and D with active update\n",
        "        flg_force_correlation : bool or None, optional (default = None)\n",
        "            force C to be a correlation matrix if True\n",
        "            None : flg_force_correlation = flg_variance_update\n",
        "        beta_eig : float, optional (default = None)\n",
        "            coefficient to control the frequency of matrix decomposition\n",
        "        beta_thresh : float, optional (default = 2.)\n",
        "            threshold parameter for beta control\n",
        "        \"\"\"\n",
        "        self.N = len(xmean0)\n",
        "        self.chiN = np.sqrt(self.N) * (1.0 - 1.0 / (4.0 * self.N) + 1.0 / (21.0 * self.N * self.N))\n",
        "\n",
        "        # options\n",
        "        self.flg_covariance_update = flg_covariance_update\n",
        "        self.flg_variance_update = flg_variance_update\n",
        "        self.flg_active_update = flg_active_update\n",
        "        self.flg_force_correlation = flg_variance_update if flg_force_correlation is None else flg_force_correlation\n",
        "        self.beta_eig = beta_eig if beta_eig else 10. * self.N\n",
        "        self.beta_thresh = beta_thresh\n",
        "\n",
        "        # parameters for recombination and step-size adaptation\n",
        "        self.lam = lam if lam else 4 + int(3 * math.log(self.N))\n",
        "        assert self.lam > 2\n",
        "        w = math.log((self.lam + 1) / 2.0) - np.log(np.arange(1, self.lam+1))\n",
        "        w[w > 0] /= np.sum(np.abs(w[w > 0]))\n",
        "        w[w < 0] /= np.sum(np.abs(w[w < 0]))\n",
        "        self.mueff_positive = 1. / np.sum(w[w > 0] ** 2)\n",
        "        self.mueff_negative = 1. / np.sum(w[w < 0] ** 2)\n",
        "        self.cm = 1.\n",
        "        self.cs = (self.mueff_positive + 2.) / (self.N + self.mueff_positive + 5.)\n",
        "        self.ds = 1. + self.cs + 2. * max(0., math.sqrt((self.mueff_positive - 1.) / (self.N + 1.)) - 1.)\n",
        "\n",
        "        # parameters for covariance matrix adaptation\n",
        "        expo = 0.75\n",
        "        mu_prime = self.mueff_positive + 1. / self.mueff_positive - 2. + self.lam / (2. * self.lam + 10.)\n",
        "        m = self.N * (self.N + 1) / 2\n",
        "        self.cone = 1. / ( 2 * (m / self.N + 1.) * (self.N + 1.) ** expo + self.mueff_positive / 2.)\n",
        "        self.cmu = min(1. - self.cone, mu_prime * self.cone)\n",
        "        self.cc = math.sqrt(self.mueff_positive * self.cone) / 2.\n",
        "        self.w = np.array(w)\n",
        "        self.w[w < 0] *= min(1. + self.cone / self.cmu, 1. + 2. * self.mueff_negative / (self.mueff_positive + 2.))\n",
        "\n",
        "        # parameters for diagonal decoding\n",
        "        m = self.N\n",
        "        self.cdone = 1. / ( 2 * (m / self.N + 1.) * (self.N + 1.) ** expo + self.mueff_positive / 2.)\n",
        "        self.cdmu = min(1. - self.cdone, mu_prime * self.cdone)\n",
        "        self.cdc = math.sqrt(self.mueff_positive * self.cdone) / 2.\n",
        "        self.wd = np.array(w)\n",
        "        self.wd[w < 0] *= min(1. + self.cdone / self.cdmu, 1. + 2. * self.mueff_negative / (self.mueff_positive + 2.))\n",
        "\n",
        "        # dynamic parameters\n",
        "        self.xmean = np.array(xmean0)\n",
        "        self.D = np.array(sigma0)\n",
        "        self.sigma = 1.\n",
        "        self.C = np.eye(self.N)\n",
        "        self.S = np.ones(self.N)\n",
        "        self.B = np.eye(self.N)\n",
        "        self.sqrtC = np.eye(self.N)\n",
        "        self.invsqrtC = np.eye(self.N)\n",
        "        self.Z = np.zeros((self.N, self.N))\n",
        "        self.pc = np.zeros(self.N)\n",
        "        self.pdc = np.zeros(self.N)\n",
        "        self.ps = np.zeros(self.N)\n",
        "        self.pc_factor = 0.\n",
        "        self.pdc_factor = 0.\n",
        "        self.ps_factor = 0.\n",
        "\n",
        "        # others\n",
        "        self.teig = max(1, int(1. / (self.beta_eig * (self.cone + self.cmu))))\n",
        "        self.neval = 0\n",
        "        self.t = 0\n",
        "        self.beta = 1.\n",
        "\n",
        "        # strage for checker and logger\n",
        "        self.arf = np.zeros(self.lam)\n",
        "        self.arx = np.zeros((self.lam, self.N))\n",
        "\n",
        "    def transform(self, z):\n",
        "        y = np.dot(z, self.sqrtC) if self.flg_covariance_update else z\n",
        "        return y * (self.D * self.sigma)\n",
        "\n",
        "    def transform_inverse(self, y):\n",
        "        z = y / (self.D * self.sigma)\n",
        "        return np.dot(z, self.invsqrtC) if self.flg_covariance_update else z\n",
        "\n",
        "    def sample(self):\n",
        "        arz = np.random.randn(self.lam, self.N)\n",
        "        ary = np.dot(arz, self.sqrtC) if self.flg_covariance_update else arz\n",
        "        arx = ary * (self.D * self.sigma) + self.xmean\n",
        "        return arx, ary, arz\n",
        "\n",
        "    def update(self, idx, arx, ary, arz):\n",
        "        # shortcut\n",
        "        w = self.w\n",
        "        wc = self.w\n",
        "        wd = self.wd\n",
        "        sarz = arz[idx]\n",
        "        sary = ary[idx]\n",
        "        sarx = arx[idx]\n",
        "\n",
        "        # recombination\n",
        "        dz = np.dot(w[w > 0], sarz[w > 0])\n",
        "        dy = np.dot(w[w > 0], sary[w > 0])\n",
        "        self.xmean += self.cm * self.sigma * self.D * dy\n",
        "\n",
        "        # step-size adaptation\n",
        "        self.ps_factor = (1 - self.cs) ** 2 * self.ps_factor + self.cs * (2 - self.cs)\n",
        "        self.ps = (1 - self.cs) * self.ps + math.sqrt(self.cs * (2 - self.cs) * self.mueff_positive) * dz\n",
        "        normsquared = np.sum(self.ps * self.ps)\n",
        "        hsig = normsquared / self.ps_factor / self.N < 2.0 + 4.0 / (self.N + 1)\n",
        "        self.sigma *= math.exp((math.sqrt(normsquared) / self.chiN - math.sqrt(self.ps_factor)) * self.cs / self.ds)\n",
        "\n",
        "        # C (intermediate) update\n",
        "        if self.flg_covariance_update:\n",
        "            # Rank-mu\n",
        "            if self.cmu == 0:\n",
        "                rank_mu = 0.\n",
        "            elif self.flg_active_update:\n",
        "                rank_mu = np.dot(sarz[wc>0].T * wc[wc>0], sarz[wc>0]) - np.sum(wc[wc>0]) * np.eye(self.N)\n",
        "                rank_mu += np.dot(sarz[wc<0].T * (wc[wc<0] * self.N / np.linalg.norm(sarz[wc<0], axis=1) ** 2),\n",
        "                                  sarz[wc<0]) - np.sum(wc[wc<0]) * np.eye(self.N)\n",
        "            else:\n",
        "                rank_mu = np.dot(sarz[wc>0].T * wc[wc>0], sarz[wc>0]) - np.sum(wc[wc>0]) * np.eye(self.N)\n",
        "            # Rank-one\n",
        "            if self.cone == 0:\n",
        "                rank_one = 0.\n",
        "            else:\n",
        "                self.pc = (1 - self.cc) * self.pc + hsig * math.sqrt(self.cc * (2 - self.cc) * self.mueff_positive) * self.D * dy\n",
        "                self.pc_factor = (1 - self.cc) ** 2 * self.pc_factor + hsig * self.cc * (2 - self.cc)\n",
        "                zpc = np.dot(self.pc / self.D, self.invsqrtC)\n",
        "                rank_one = np.outer(zpc, zpc) - self.pc_factor * np.eye(self.N)\n",
        "            # Update\n",
        "            self.Z += (self.cmu * rank_mu + self.cone * rank_one)\n",
        "\n",
        "        # D update\n",
        "        if self.flg_variance_update:\n",
        "            # Cumulation\n",
        "            self.pdc = (1 - self.cdc) * self.pdc + hsig * math.sqrt(self.cdc * (2 - self.cdc) * self.mueff_positive) * self.D * dy\n",
        "            self.pdc_factor = (1 - self.cdc) ** 2 * self.pdc_factor + hsig * self.cdc * (2 - self.cdc)\n",
        "            DD = self.cdone * (np.dot(self.pdc / self.D, self.invsqrtC) ** 2 - self.pdc_factor)\n",
        "            if self.flg_active_update:\n",
        "                # positive and negative update\n",
        "                DD += self.cdmu * np.dot(wd[wd>0], sarz[wd>0] ** 2)\n",
        "                DD += self.cdmu * np.dot(wd[wd<0] * self.N / np.linalg.norm(sarz[wd<0], axis=1)**2, sarz[wd<0]**2)\n",
        "                DD -= self.cdmu * np.sum(wd)\n",
        "            else:\n",
        "                # positive update\n",
        "                DD += self.cdmu * np.dot(wd[wd>0], sarz[wd>0] ** 2)\n",
        "                DD -= self.cdmu * np.sum(wd[wd>0])\n",
        "            if self.flg_covariance_update:\n",
        "                self.beta = 1 / max(1, np.max(self.S) / np.min(self.S) - self.beta_thresh + 1.)\n",
        "            else:\n",
        "                self.beta = 1.\n",
        "            self.D *= np.exp((self.beta / 2) * DD)\n",
        "\n",
        "        # update C\n",
        "        if self.flg_covariance_update and (self.t + 1) % self.teig == 0:\n",
        "            D = np.linalg.eigvalsh(self.Z)\n",
        "            fac = min(0.75 / abs(D.min()), 1.)\n",
        "            self.C = np.dot(np.dot(self.sqrtC, np.eye(self.N) + fac * self.Z), self.sqrtC)\n",
        "\n",
        "            # force C to be correlation matrix\n",
        "            if self.flg_force_correlation:\n",
        "                cd = np.sqrt(np.diag(self.C))\n",
        "                self.D *= cd\n",
        "                self.C = (self.C / cd).T / cd\n",
        "\n",
        "            # decomposition\n",
        "            DD, self.B = np.linalg.eigh(self.C)\n",
        "            self.S = np.sqrt(DD)\n",
        "            self.sqrtC = np.dot(self.B * self.S, self.B.T)\n",
        "            self.invsqrtC = np.dot(self.B / self.S, self.B.T)\n",
        "            self.Z[:, :] = 0.\n",
        "\n",
        "    def onestep(self, func):\n",
        "        \"\"\"\n",
        "        Parameter\n",
        "        ---------\n",
        "        func : callable\n",
        "            parameter : 2d array-like with candidate solutions (x) as elements\n",
        "            return    : 1d array-like with f(x) as elements\n",
        "        \"\"\"\n",
        "        # sampling\n",
        "        arx, ary, arz = self.sample()\n",
        "\n",
        "        # evaluation\n",
        "        arf = func(arx)\n",
        "        self.neval += len(arf)\n",
        "\n",
        "        # sort\n",
        "        idx = np.argsort(arf)\n",
        "        if not np.all(arf[idx[1:]] - arf[idx[:-1]] > 0.):\n",
        "            warnings.warn(\"assumed no tie, but there exists\", RuntimeWarning)\n",
        "\n",
        "        # update\n",
        "        self.update(idx, arx, ary, arz)\n",
        "\n",
        "        # finalize\n",
        "        self.t += 1\n",
        "        self.arf = arf\n",
        "        self.arx = arx\n",
        "\n",
        "    def upper_bounding_coordinate_std(self, coordinate_length):\n",
        "        \"\"\"Upper-bounding coordinate-wise standard deviation\n",
        "\n",
        "        When some design variables are periodic, the coordinate-wise standard deviation\n",
        "        should be upper-bounded by r_i / 4, where r_i is the period of the ith variable.\n",
        "        The correction of the overall covariance matrix, Sigma, is done as follows:\n",
        "            Sigma = Correction * Sigma * Correction,\n",
        "        where Correction is a diagonal matrix defined as\n",
        "            Correction_i = min( r_i / (4 * Sigma_{i,i}^{1/2}), 1 ).\n",
        "\n",
        "        In DD-CMA, the correction matrix is simply multiplied to D.\n",
        "\n",
        "        For example, if a mirroring box constraint handling is used for a box constraint\n",
        "        [l_i, u_i], the variables become periodic on [l_i - (u_i-l_i)/2, u_i + (u_i-l_i)/2].\n",
        "        Therefore, the period is\n",
        "            r_i = 2 * (u_i - l_i).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        coordinate_length : ndarray (1D) or float\n",
        "            coordinate-wise search length r_i.\n",
        "\n",
        "        References\n",
        "        ----------\n",
        "        T. Yamaguchi and Y. Akimoto.\n",
        "        A Note on the CMA-ES for Functions with Periodic Variables.\n",
        "        GECCO '18 Companion, pages 227--228 (2018)\n",
        "        \"\"\"\n",
        "        correction = np.fmin(coordinate_length / self.coordinate_std / 4.0, 1)\n",
        "        self.D *= correction\n",
        "\n",
        "\n",
        "    @property\n",
        "    def coordinate_std(self):\n",
        "        if self.flg_covariance_update:\n",
        "            return self.sigma * self.D * np.sqrt(np.diag(self.C))\n",
        "        else:\n",
        "            return self.sigma * self.D\n",
        "\n",
        "class Checker:\n",
        "    \"\"\"BBOB ermination Checker for dd-CMA\"\"\"\n",
        "    def __init__(self, cma):\n",
        "        assert isinstance(cma, DdCma)\n",
        "        self._cma = cma\n",
        "        self._init_std = self._cma.coordinate_std\n",
        "        self._N = self._cma.N\n",
        "        self._lam = self._cma.lam\n",
        "        self._hist_fbest = deque(maxlen=10 + int(np.ceil(30 * self._N / self._lam)))\n",
        "        self._hist_feq_flag = deque(maxlen=self._N)\n",
        "        self._hist_fmin = deque()\n",
        "        self._hist_fmed = deque()\n",
        "\n",
        "    def __call__(self):\n",
        "        return self.bbob_check()\n",
        "\n",
        "    def check_maxiter(self):\n",
        "        return self._cma.t > 100 + 50 * (self._N + 3) ** 2 / np.sqrt(self._lam)\n",
        "\n",
        "    def check_tolhistfun(self):\n",
        "        self._hist_fbest.append(np.min(self._cma.arf))\n",
        "        return (self._cma.t >= 10 + int(np.ceil(30 * self._N / self._lam)) and\n",
        "                np.max(self._hist_fbest) - np.min(self._hist_fbest) < 1e-12)\n",
        "\n",
        "    def check_equalfunvals(self):\n",
        "        k = int(math.ceil(0.1 + self._lam / 4))\n",
        "        sarf = np.sort(self._cma.arf)\n",
        "        self._hist_feq_flag.append(sarf[0] == sarf[k])\n",
        "        return 3 * sum(self._hist_feq_flag) > self._N\n",
        "\n",
        "    def check_tolx(self):\n",
        "        return (np.all(self._cma.coordinate_std / self._init_std) < 1e-12)\n",
        "\n",
        "    def check_tolupsigma(self):\n",
        "        return np.any(self._cma.coordinate_std / self._init_std > 1e3)\n",
        "\n",
        "    def check_stagnation(self):\n",
        "        self._hist_fmin.append(np.min(self._cma.arf))\n",
        "        self._hist_fmed.append(np.median(self._cma.arf))\n",
        "        _len = int(np.ceil(self._cma.t / 5 + 120 + 30 * self._N / self._lam))\n",
        "        if len(self._hist_fmin) > _len:\n",
        "            self._hist_fmin.popleft()\n",
        "            self._hist_fmed.popleft()\n",
        "        fmin_med = np.median(np.asarray(self._hist_fmin)[-20:])\n",
        "        fmed_med = np.median(np.asarray(self._hist_fmed)[:20])\n",
        "        return self._cma.t >= _len and fmin_med >= fmed_med\n",
        "\n",
        "    def check_conditioncov(self):\n",
        "        return (np.max(self._cma.S) / np.min(self._cma.S) > 1e7\n",
        "                or np.max(self._cma.D) / np.min(self._cma.D) > 1e7)\n",
        "\n",
        "    def check_noeffectaxis(self):\n",
        "        t = self._cma.t % self._N\n",
        "        test = 0.1 * self._cma.sigma * self._cma.D * self._cma.S[t] * self._cma.B[:, t]\n",
        "        return np.all(self._cma.xmean == self._cma.xmean + test)\n",
        "\n",
        "    def check_noeffectcoor(self):\n",
        "        return np.all(self._cma.xmean == self._cma.xmean + 0.2 * self._cma.coordinate_std)\n",
        "\n",
        "    def check_flat(self):\n",
        "        return np.max(self._cma.arf) == np.min(self._cma.arf)\n",
        "\n",
        "    def bbob_check(self):\n",
        "        if self.check_maxiter():\n",
        "            return True, 'bbob_maxiter'\n",
        "        if self.check_tolhistfun():\n",
        "            return True, 'bbob_tolhistfun'\n",
        "        if self.check_equalfunvals():\n",
        "            return True, 'bbob_equalfunvals'\n",
        "        if self.check_tolx():\n",
        "            return True, 'bbob_tolx'\n",
        "        if self.check_tolupsigma():\n",
        "            return True, 'bbob_tolupsigma'\n",
        "        if self.check_stagnation():\n",
        "            return True, 'bbob_stagnation'\n",
        "        if self.check_conditioncov():\n",
        "            return True, 'bbob_conditioncov'\n",
        "        if self.check_noeffectaxis():\n",
        "            return True, 'bbob_noeffectaxis'\n",
        "        if self.check_noeffectcoor():\n",
        "            return True, 'bbob_noeffectcoor'\n",
        "        if self.check_flat():\n",
        "            return True, 'bbob_flat'\n",
        "        return False, ''\n",
        "\n",
        "\n",
        "class Logger:\n",
        "    \"\"\"Logger for dd-CMA\"\"\"\n",
        "    def __init__(self, cma, prefix='log', variable_list=['xmean', 'D', 'S', 'sigma', 'beta']):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        cma : DdCma instance\n",
        "        prefix : string\n",
        "            prefix for the log file path\n",
        "        variable_list : list of string\n",
        "            list of names of attributes of `cma` to be monitored\n",
        "        \"\"\"\n",
        "        self._cma = cma\n",
        "        self.neval_offset = 0\n",
        "        self.t_offset = 0\n",
        "        self.prefix = prefix\n",
        "        self.variable_list = variable_list\n",
        "        self.logger = dict()\n",
        "        self.fmin_logger = self.prefix + '_fmin.dat'\n",
        "        with open(self.fmin_logger, 'w') as f:\n",
        "            f.write('#' + type(self).__name__ + \"\\n\")\n",
        "        for key in self.variable_list:\n",
        "            self.logger[key] = self.prefix + '_' + key + '.dat'\n",
        "            with open(self.logger[key], 'w') as f:\n",
        "                f.write('#' + type(self).__name__ + \"\\n\")\n",
        "\n",
        "    def __call__(self, condition=''):\n",
        "        self.log(condition)\n",
        "\n",
        "    def setcma(self, cma):\n",
        "        self.neval_offset += self._cma.neval\n",
        "        self.t_offset += self._cma.t\n",
        "        self._cma = cma\n",
        "\n",
        "    def log(self, condition=''):\n",
        "        neval = self.neval_offset + self._cma.neval\n",
        "        t = self.t_offset + self._cma.t\n",
        "        with open(self.fmin_logger, 'a') as f:\n",
        "            f.write(\"{} {} {}\\n\".format(t, neval, np.min(self._cma.arf)))\n",
        "            if condition:\n",
        "                f.write('# End with condition = ' + condition)\n",
        "        for key, log in self.logger.items():\n",
        "            key_split = key.split('.')\n",
        "            key = key_split.pop(0)\n",
        "            var = getattr(self._cma, key)\n",
        "            for i in key_split:\n",
        "                var = getattr(var, i)\n",
        "            if isinstance(var, np.ndarray) and len(var.shape) > 1:\n",
        "                var = var.flatten()\n",
        "            varlist = np.hstack((t, neval, var))\n",
        "            with open(log, 'a') as f:\n",
        "                f.write(' '.join(map(repr, varlist)) + \"\\n\")\n",
        "\n",
        "    def my_formatter(self, x, pos):\n",
        "        \"\"\"Float Number Format for Axes\"\"\"\n",
        "        float_str = \"{0:2.1e}\".format(x)\n",
        "        if self.latexmode:\n",
        "            if \"e\" in float_str:\n",
        "                base, exponent = float_str.split(\"e\")\n",
        "                return r\"{0}e{1}\".format(base, int(exponent))\n",
        "            else:\n",
        "                return r\"\" + float_str + \"\"\n",
        "        else:\n",
        "            if \"e\" in float_str:\n",
        "                base, exponent = float_str.split(\"e\")\n",
        "                return \"{0}e{1}\".format(base, int(exponent))\n",
        "            else:\n",
        "                return \"\" + float_str + \"\"\n",
        "\n",
        "    def plot(self,\n",
        "             xaxis=0,\n",
        "             ncols=None,\n",
        "             figsize=None,\n",
        "             cmap_='Spectral',\n",
        "             latexmode=False):\n",
        "\n",
        "        \"\"\"Plot the result\n",
        "        Parameters\n",
        "        ----------\n",
        "        xaxis : int, optional (default = 0)\n",
        "            0. vs iterations\n",
        "            1. vs function evaluations\n",
        "        ncols : int, optional (default = None)\n",
        "            number of columns\n",
        "        figsize : tuple, optional (default = None)\n",
        "            figure size\n",
        "        cmap_ : string, optional (default = 'spectral')\n",
        "            cmap\n",
        "        latexmode : bool, optional (default = False)\n",
        "            LaTeX is enabled if this is True\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        fig : figure object.\n",
        "            figure object\n",
        "        axdict : dictionary of axes\n",
        "            the keys are the names of variables given in `variable_list`\n",
        "        \"\"\"\n",
        "        self.latexmode = latexmode\n",
        "\n",
        "        mpl.rc('lines', linewidth=2, markersize=8)\n",
        "        mpl.rc('font', size=12)\n",
        "        mpl.rc('grid', color='0.75', linestyle=':')\n",
        "        if self.latexmode:\n",
        "            mpl.rc('text', usetex=True)  # for a paper submision\n",
        "            mpl.rc('ps', useafm=True)  # Force to use\n",
        "            mpl.rc('pdf', use14corefonts=True)  # only Type 1 fonts\n",
        "        prefix = self.prefix\n",
        "        variable_list = self.variable_list\n",
        "\n",
        "        # Default settings\n",
        "        nfigs = 1 + len(variable_list)\n",
        "        if ncols is None:\n",
        "            ncols = int(np.ceil(np.sqrt(nfigs)))\n",
        "        nrows = int(np.ceil(nfigs / ncols))\n",
        "        if figsize is None:\n",
        "            figsize = (4 * ncols, 3 * nrows)\n",
        "        axdict = dict()\n",
        "\n",
        "        # Figure\n",
        "        fig = plt.figure(figsize=figsize)\n",
        "        # The first figure\n",
        "        x = np.loadtxt(prefix + '_fmin.dat')\n",
        "        x = x[~np.isnan(x[:, xaxis]), :]  # remove columns where xaxis is nan\n",
        "        # Axis\n",
        "        ax = plt.subplot(nrows, ncols, 1)\n",
        "        ax.set_title('fmin')\n",
        "        ax.grid(True)\n",
        "        ax.grid(which='major', linewidth=0.50)\n",
        "        ax.grid(which='minor', linewidth=0.25)\n",
        "        plt.plot(x[:, xaxis], x[:, 2:])\n",
        "        ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(self.my_formatter))\n",
        "        ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(self.my_formatter))\n",
        "        axdict['fmin'] = ax\n",
        "\n",
        "        # The other figures\n",
        "        idx = 1\n",
        "        for key in variable_list:\n",
        "            idx += 1\n",
        "            x = np.loadtxt(prefix + '_' + key + '.dat')\n",
        "            x = x[~np.isnan(\n",
        "                x[:, xaxis]), :]  # remove columns where xaxis is nan\n",
        "            ax = plt.subplot(nrows, ncols, idx)\n",
        "            if self.latexmode:\n",
        "                ax.set_title(r'\\detokenize{' + key + '}')\n",
        "            else:\n",
        "                ax.set_title(key)\n",
        "            ax.grid(True)\n",
        "            ax.grid(which='major', linewidth=0.50)\n",
        "            ax.grid(which='minor', linewidth=0.25)\n",
        "            cmap = plt.get_cmap(cmap_)\n",
        "            cNorm = mpl.colors.Normalize(vmin=0, vmax=x.shape[1] - 2)\n",
        "            scalarMap = mpl.cm.ScalarMappable(norm=cNorm, cmap=cmap)\n",
        "            for i in range(x.shape[1] - 2):\n",
        "                plt.plot(\n",
        "                    x[:, xaxis], x[:, 2 + i], color=scalarMap.to_rgba(i))\n",
        "            ax.xaxis.set_major_formatter(\n",
        "                mpl.ticker.FuncFormatter(self.my_formatter))\n",
        "            ax.yaxis.set_major_formatter(\n",
        "                mpl.ticker.FuncFormatter(self.my_formatter))\n",
        "            axdict[key] = ax\n",
        "\n",
        "        plt.tight_layout() # NOTE: not sure if it works fine\n",
        "        return fig, axdict\n",
        "\n",
        "def random_rotation(self, func, dim):\n",
        "    R = np.random.normal(0, 1, (dim, dim))\n",
        "    for i in range(dim):\n",
        "        for j in range(i):\n",
        "            R[:, i] = R[:, i] - np.dot(R[:, i], R[:, j]) * R[:, j]\n",
        "        R[:, i] = R[:, i] / np.linalg.norm(R[:, i])\n",
        "    def rotatedfunc(x):\n",
        "        return func(np.dot(x, R.T))\n",
        "    return rotatedfunc\n",
        "\n",
        "def mirror(z, lbound, ubound, flg_periodic):\n",
        "    \"\"\"Mirroring Box-Constraint Handling and Periodic Constraint Handling\n",
        "    Parameters\n",
        "    ----------\n",
        "    z : ndarray (1D or 2D)\n",
        "        solutions to be corrected\n",
        "    lbound, ubound : ndarray (1D)\n",
        "        lower and upper bounds\n",
        "        If some variables are not bounded, set np.inf or -np.inf\n",
        "    flg_periodic : ndarray (1D, bool)\n",
        "        flag for periodic variables\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    projected solution in [lbound, ubound]\n",
        "    \"\"\"\n",
        "    zz = np.copy(z)\n",
        "    flg_lower = np.isfinite(lbound) * np.logical_not(np.isfinite(ubound) + flg_periodic)\n",
        "    flg_upper = np.isfinite(ubound) * np.logical_not(np.isfinite(lbound) + flg_periodic)\n",
        "    flg_box = np.isfinite(lbound) * np.isfinite(ubound) * np.logical_not(flg_periodic)\n",
        "    width = ubound - lbound\n",
        "    if zz.ndim == 1:\n",
        "        zz[flg_periodic] = lbound[flg_periodic] + np.mod(zz[flg_periodic] - lbound[flg_periodic], width[flg_periodic])\n",
        "        zz[flg_lower] = lbound[flg_lower] + np.abs(zz[flg_lower] - lbound[flg_lower])\n",
        "        zz[flg_upper] = ubound[flg_upper] - np.abs(zz[flg_upper] - ubound[flg_upper])\n",
        "        zz[flg_box] = ubound[flg_box] - np.abs(np.mod(zz[flg_box] - lbound[flg_box], 2 * width[flg_box]) - width[flg_box])\n",
        "    elif zz.ndim == 2:\n",
        "        zz[:, flg_periodic] = lbound[flg_periodic] + np.mod(zz[:, flg_periodic] - lbound[flg_periodic], width[flg_periodic])\n",
        "        zz[:, flg_lower] = lbound[flg_lower] + np.abs(zz[:, flg_lower] - lbound[flg_lower])\n",
        "        zz[:, flg_upper] = ubound[flg_upper] - np.abs(zz[:, flg_upper] - ubound[flg_upper])\n",
        "        zz[:, flg_box] = ubound[flg_box] - np.abs(np.mod(zz[:, flg_box] - lbound[flg_box], 2 * width[flg_box]) - width[flg_box])\n",
        "    return zz\n",
        "\n"
      ],
      "metadata": {
        "id": "-DJ1eHt9PSWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 実行スクリプト\n",
        "10次元の凹凸二次関数に対して，上で紹介したナイーブなアプローチを適用する．シナリオのサンプル数は10とする．\n",
        "定義域は$[-5, 5]^N \\times [-5, 5]^N$とする．"
      ],
      "metadata": {
        "id": "jhCTPaeEVLbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 簡単のため， x と y の次元数は等しいとする．\n",
        "N = 10\n",
        "a = c = 1.0\n",
        "b = 10.0\n",
        "\n",
        "def f(x, y):\n",
        "    return a * np.dot(x, x) + b * np.dot(x, y) - c * np.dot(y, y)\n",
        "\n",
        "def f_worst(x):\n",
        "    y = b * x / 2 / c\n",
        "    return f(x, y)\n",
        "\n",
        "# シナリオサンプル．ここでは標準正規分布からサンプリング\n",
        "np.random.seed(100)\n",
        "M = 10\n",
        "y_array = np.random.randn(M, N)\n",
        "def f_worst_approx(x):\n",
        "    return max([f(x, y) for y in y_array])\n",
        "\n",
        "# Support for box constraint and periodic variables\n",
        "# Set np.nan, -np.inf or np.inf if no bound\n",
        "LOWER_BOUND = -5.0 * np.ones(N)\n",
        "UPPER_BOUND = 5.0 * np.ones(N)\n",
        "FLAG_PERIODIC = np.asarray([False] * N)\n",
        "period_length = (UPPER_BOUND - LOWER_BOUND) * 2.0\n",
        "period_length[FLAG_PERIODIC] /= 2.0\n",
        "period_length[np.logical_not(np.isfinite(period_length))] = np.inf\n",
        "\n",
        "def fobj(x):\n",
        "    xx = mirror(x, LOWER_BOUND, UPPER_BOUND, FLAG_PERIODIC)\n",
        "    if np.ndim(xx) == 1:\n",
        "        return np.array([f_worst_approx(xx)])\n",
        "    else:\n",
        "        return np.array([f_worst_approx(xxx) for xxx in xx])\n",
        "\n",
        "# Stopping Condition\n",
        "F_TARGET = -np.inf   # target function value\n",
        "\n",
        "# Main loop\n",
        "ddcma = DdCma(xmean0=np.random.randn(N), sigma0=np.ones(N)*2.)\n",
        "ddcma.upper_bounding_coordinate_std(period_length)\n",
        "checker = Checker(ddcma)\n",
        "logger = Logger(ddcma)\n",
        "\n",
        "issatisfied = False\n",
        "fbestsofar = np.inf\n",
        "while not issatisfied:\n",
        "    ddcma.onestep(func=fobj)\n",
        "    ddcma.upper_bounding_coordinate_std(period_length)\n",
        "    fbest = np.min(ddcma.arf)\n",
        "    fbestsofar = min(fbest, fbestsofar)\n",
        "    if fbest <= F_TARGET:\n",
        "        issatisfied, condition = True, 'ftarget'\n",
        "    else:\n",
        "        issatisfied, condition = checker()\n",
        "    if ddcma.t % 10 == 0:\n",
        "        print(ddcma.t, ddcma.neval, fbest, fbestsofar)\n",
        "        logger()\n",
        "logger(condition)\n",
        "print(\"Terminated with condition: \" + str(condition))\n",
        "\n",
        "# Produce a figure\n",
        "fig, axdict = logger.plot()\n",
        "for key in axdict:\n",
        "    if key not in ('xmean'):\n",
        "        axdict[key].set_yscale('log')\n",
        "plt.tight_layout()\n",
        "plt.savefig(logger.prefix + '.pdf')"
      ],
      "metadata": {
        "id": "9lg_VUYBUsl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "解を生成している正規分布の平均ベクトル（xmean）について，近似最悪性能と真の最悪性能の変化をプロットしてみる．"
      ],
      "metadata": {
        "id": "46y3_YbVPKqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xmean_hist = np.loadtxt('log_xmean.dat')\n",
        "fxmean_worst_approx_hist = np.array([f_worst_approx(x) for x in xmean_hist[:, 2:]])\n",
        "fxmean_worst_hist = np.array([f_worst(x) for x in xmean_hist[:, 2:]])\n",
        "plt.plot(xmean_hist[:, 0], fxmean_worst_approx_hist, label=r'$\\tilde{F}_Y$')\n",
        "plt.plot(xmean_hist[:, 0], fxmean_worst_hist, label=r'$F_Y$')\n",
        "plt.xlabel('iterations')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "RIs0HsjAN1II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "最終イテレーションでの平均ベクトルの値は以下の通り．"
      ],
      "metadata": {
        "id": "f2iJW91ZPfnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xmean_hist[-1, 2:]"
      ],
      "metadata": {
        "id": "IH6C6txcPbxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上の結果からわかるように，得られた解は真の最悪性能$F_Y$の最適解である$x^* = 0$から乖離しており，得られた解の最悪性能は真のそれ（$F_Y(x^*) = 0$）と比較して大きな値となっている．今回の問題の場合，主な原因は\n",
        "\n",
        "1. サンプルしたシナリオ数がD=１０次元の不確実性空間においてM=10点のみとなっており，真の最悪性能を十分に良く近似することができないため\n",
        "\n",
        "と考えられる．\n",
        "これとは独立に，もう一つの困難さとして，\n",
        "\n",
        "2. 近似最悪性能関数$\\tilde{F}_Y$の局所解は多くの場合，複数のシナリオによって構成される部分の接点となっており，局所的に滑らかでない等高線を持つ関数となっている\n",
        "\n",
        "という点も挙げておく．ただし，この問題の場合，１点目が大きな問題であるため，２点目がメインの困難さではないことに注意されたい．"
      ],
      "metadata": {
        "id": "L95roPWBaFQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adversarial-CMA-ES\n",
        "\n",
        "Adversarial-CMA-ES は$x$についての最小化と$y$についての最大化を交互に実施することで，目的関数$f(x, y)$のミニマックス鞍点を求めることを目的として設計されている．\n",
        "ここで，ミニマックス鞍点$(x^*, y^*)$とは，その近傍において\n",
        "$$\n",
        "f(x, y^*) > f(x^*, y^*) > f(x^*, y)\n",
        "$$\n",
        "が近傍上の任意の$(x, y)$について成り立つような点を表す．\n",
        "すなわち，$x^*$のもとで$y^*$は局所的に目的関数$f(x^*, y)$を最大にする点であり，同時に，$y^*$のもとで$x^*$は局所的に目的関数$f(x, y^*)$を最小化する点である．\n",
        "大域的なミニマックス鞍点がある場合，すなわち，任意の$(x, y)$に対して上の不等式が成立するような$(x^*, y^*)$が存在する場合には，そのような$x^*$が最悪性能$F_Y$の最適解である．\n",
        "目的関数が狭義凹凸関数である場合には，最適解がミニマックス鞍点となることが知られており，ミニマックス鞍点を求めることが最適解を求めることに繋がる．\n",
        "しかし，一般には，最悪性能$F_Y$の下での最適解がミニマックス鞍点となるとは限らないことに注意されたい．\n",
        "\n"
      ],
      "metadata": {
        "id": "aO_GbUoKPx7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 交互最適化\n",
        "\n",
        "基本的なアイディアは，以下の最適化を交互に繰り返すことである．\n",
        "\n",
        "* $x$ を固定して，$y = \\mathrm{argmax}_y f(x, y)$を求める．\n",
        "* $y$ を固定して，$x = \\mathrm{argmin}_x f(x, y)$を求める．\n",
        "\n",
        "しかし，これを単純に実行しても，限られた状況を除いてミニマックス鞍点に収束せず，発散する恐れがある．\n",
        "例えば，上に挙げた凹凸二次関数\n",
        "$$\n",
        "f(x, y) = a x^2 + b x y - c y^2\n",
        "$$\n",
        "を考える．\n",
        "各$y$について最適な$x$は\n",
        "$$\n",
        "x^*(y) = \\frac{-by}{2a}\n",
        "$$\n",
        "であり，各$x$について最適な$y$は\n",
        "$$\n",
        "y^*(x) = \\frac{b x}{2 c}\n",
        "$$\n",
        "である．適当な $x^{(0)}$からスタートして，$y^{(0)} = y^*(x^{(0)})$, $x^{(1)} = x^*(y^{(0)})$, ... と繰り返していくと，\n",
        "$$\n",
        "x^{(t)} = \\left(\\frac{-b^2}{4ac}\\right)^t x^{(0)}\n",
        "$$\n",
        "となる．\n",
        "容易にわかるように，$b^2 > 4|ac|$の場合にはこのプロセスは発散してしまい，ミニマックス鞍点$(0, 0)$を求めることができない．\n",
        "なお，$b^2$が$4|ac|$と比較して大きいということは，$x$と$y$の依存関係が強いことを意味している．"
      ],
      "metadata": {
        "id": "N7XOEY3-2e3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adversarial-CMA-ES のアイディア\n",
        "\n",
        "交互最適化における上述の問題を回避するため，交互最適化の結果を利用して候補解を少しずつ更新していく方法を採用する．\n",
        "初期の候補を$(x^{(0)}, y^{(0)})$として，\n",
        "$$\n",
        "\\begin{aligned}\n",
        "x^{(t+1)} &= x^{(t)} + \\eta (x^*(y^{(t)}) - x^{(t)}) \\\\\n",
        "y^{(t+1)} &= y^{(t)} + \\eta (y^*(x^{(t)}) - y^{(t)})\n",
        "\\end{aligned}\n",
        "$$\n",
        "のように学習率$\\eta > 0$を設けて更新していく．\n",
        "十分に小さな$\\eta$を設定することで，上述の問題を回避することができる．\n",
        "\n",
        "先の凹凸二次関数を用いてこれが解決法になっていることを確認する．\n",
        "簡単のため，$a = c = 1$の場合に限って考えることにする．\n",
        "いま $t$ iteration での候補解のペアを$z^{(t)} = [x^{(t)}, y^{(t)}]^\\mathrm{T}$とすれば， 1 iteration 後の候補解は\n",
        "$$\n",
        "z^{(t+1)}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "x^{(t+1)} \\\\\n",
        "y^{(t+1)}\n",
        "\\end{bmatrix}\n",
        "=\\underbrace{\n",
        "\\begin{bmatrix}\n",
        "1 - \\eta & - \\frac{b}{2}\\eta \\\\\n",
        "\\frac{b}{2}\\eta & 1 - \\eta\n",
        "\\end{bmatrix}}_{=:A}\n",
        "\\begin{bmatrix}\n",
        "x^{(t)} \\\\\n",
        "y^{(t)}\n",
        "\\end{bmatrix}\n",
        "=\n",
        "A z^{(t)}\n",
        "= A^{t+1} z^{(0)}\n",
        "$$\n",
        "となる．\n",
        "したがって，行列$A$の特異値が全て$1$未満であれば，$z^{(t)} \\to [0, 0]^\\mathrm{T}$に収束する．\n",
        "ここで，行列$A$の特異値を求める．\n",
        "行列$A$の特異値は，$A A^\\mathrm{T}$の固有値の平方根にほかならないが，\n",
        "$$\n",
        "A A^\\mathrm{T}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "1 - \\eta & - \\frac{b}{2}\\eta \\\\\n",
        "\\frac{b}{2}\\eta & 1 - \\eta\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "1 - \\eta & \\frac{b}{2}\\eta \\\\\n",
        "- \\frac{b}{2}\\eta & 1 - \\eta\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "(1 - \\eta)^2 + \\frac{b^2}{4}\\eta^2 & 0 \\\\\n",
        "0 & (1 - \\eta)^2 + \\frac{b^2}{4}\\eta^2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "であることから，２つの特異値はいずれも$\\sqrt{(1 - \\eta)^2 + \\frac{b^2}{4}\\eta^2}$である．\n",
        "これは，$\\eta < \\frac{8}{4 + b^2}$の場合に$1$未満となる．\n",
        "したがって，十分に小さな$\\eta$のもとで，この繰り返し法は収束することになる．\n",
        "なお，収束の速さはこの特異値によって定まるが，$b$が大きいほど特異値を$1$未満にするための$\\eta$が小さくなり，その結果特異値が$1$に近づくことになる．\n",
        "すなわち，$b$が大きいほど，$\\eta$を適切に選択したとしても収束は遅くなる．\n",
        "\n",
        "上の議論では簡単のため，厳密な$x^*(y)$や$y^*(x)$を考えたが，これらは一般に解析的には求まらないため，最適化によって近似することが必要になる．\n",
        "すなわち，誤差を含むことになる．\n",
        "他方，小さな$\\eta$を用いて更新していく場合，$x^*(y)$や$y^*(x)$に誤差が加わったとしても，更新すべき方向$x^*(y^{(t)}) - x^{(t)}$や$y^*(x^{(t)}) - y^{(t)}$が大きく変わらない限り，誤差があっても正しく収束させることが可能である．\n",
        "詳しくは文献[1]を参照されたい．"
      ],
      "metadata": {
        "id": "UPMSkc_M2gZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 実装について\n",
        "\n",
        "* 各パラメータの最適化は(1+1)-CMA-ESにより行う．\n",
        "各最適化ステップにおいて厳密な$x^*$や$y^*$は不要である．\n",
        "Adversarial-CMA-ESでは，(1+1)-CMA-ESがLipschitz smoothかつstrongly convexな関数のもとで指数的に収束していき（一次収束），そのレートが1/dに比例する（dは設計変数の次元数）という理論結果に基づき，各ステップにおいて(1+1)-CMA-ESをO(d)イテレーション実行し，その結果として得られた解を$x^*$や$y^*$の近似解として採用する．\n",
        "\n",
        "* 最適な$\\eta$を予めしることはできないため，適応的に調整している．\n",
        "具体的には，ギャップ関数\n",
        "$$\n",
        "G(x, y) = \\max_{y'} f(x, y') - \\min_{x'} f(x', y)\n",
        "$$\n",
        "を近似し，これがAdversarial-CMA-ESの各更新において最も高速に減少していくように$\\eta$を適応する．\n",
        "なお，ギャップ関数とミニマックス鞍点の関係については文献を参照されたい．\n",
        "\n",
        "* Adversarial-CMA-ESはミニマックス鞍点を求めることに着目しているが，ミニマックス最適化の最適解がミニマックス鞍点になっている保証はない．\n",
        "そこで，Adversarial-CMA-ESでは，ミニマックス鞍点の近似解を発見するたびにこれを保存し，探索を再度実行する．\n",
        "その際，前述のナイーブな方法のアイディアを用いて，目的関数を\n",
        "$$\n",
        "F(x, y) = \\max\\{f(x, y), f(x, y_1), \\dots, f(x, y_K)\\}\n",
        "$$\n",
        "のように拡張し，Adversarial-CMA-ESを適用する．\n",
        "ここで，$y_k$は$k$回目の探索で得られたミニマックス鞍点の近似解である．\n",
        "これにより，凹凸関数でない場合にも，ナイーブな方法と同様に実用上ある程度はロバストな解が得られることが期待される．"
      ],
      "metadata": {
        "id": "W10Qz58Loc_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adversarial-CMA-ESのコード\n",
        "以下はレポジトリ（　https://gist.github.com/youheiakimoto/ab51e88c73baf68effd95b750100aad0　）からのコピー．\n",
        "主な機能は以下の２つ：\n",
        "\n",
        "* 関数 minmax：Adversarial-CMA-ESを実行する関数であり，最大評価回数に達するまでに自動的にリスタートがかかるようになっている．\n",
        "\n",
        "* 関数 worstsearch：ミニマックス最適化が終了した後，最悪性能をより正確に評価するために，得られた解$x^*$のもとでの目的関数$f(x^*, y)$の最大化を行っている．\n",
        "今回のテスト関数の場合には真の最悪性能を計算できるため不要であるが，通常は真の最悪性能が評価できないためこのような評価を行う必要がある．\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zwLtKIf3oKyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\"\"\"Adversarial-CMA-ES: derivative-free min-max optimization solver using (1+1)-CMA-ES [1]\n",
        "It is an extention of Adversarial Evolution Strategy [2]\n",
        "(https://gist.github.com/youheiakimoto/15212dbf46dc546af20af38b0b48ff17)\n",
        "Reference\n",
        "---------\n",
        "[1] Youhei Akimoto, Yoshiki Miyauchi, and Atsuo Maki. 2022.\n",
        "Saddle Point Optimization with Approximate Minimization Oracle and Its Application to Robust Berthing Control.\n",
        "ACM Trans. Evol. Learn. Optim. 2, 1, Article 2 (March 2022), 32 pages.\n",
        "DOI:https://doi.org/10.1145/3510425\n",
        "[2] Youhei Akimoto. 2021.\n",
        "Saddle point optimization with approximate minimization oracle.\n",
        "In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO '21).\n",
        "Association for Computing Machinery, New York, NY, USA, 493–501.\n",
        "DOI:https://doi.org/10.1145/3449639.3459266\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class Cmaes:\n",
        "    \"\"\"(1+1)-Active-CMA-ES [Arnold 2010] with Simplified 1/5th Success Rule\"\"\"\n",
        "\n",
        "    def __init__(self, dim, tau, tau_offset, tolsigma=0.0, tolh=-np.inf, verbose=False):\n",
        "        self.verbose = verbose\n",
        "        self.tolsigma = tolsigma\n",
        "        self.tolh = tolh\n",
        "\n",
        "        self.dim = dim\n",
        "        self.tau = tau\n",
        "        self.tau_offset = tau_offset\n",
        "\n",
        "        self.rescale_itr = 0\n",
        "\n",
        "        self.aup = np.exp(2.0 / (2.0 + self.dim))\n",
        "        self.adown = self.aup ** (-0.25)\n",
        "        self.pthresh = 0.44\n",
        "        self.cp = 1.0 / 12.0\n",
        "        self.cc = 2.0 / (self.dim + 2)\n",
        "        self.ccovp = 2.0 / (self.dim**2 + 6)\n",
        "        self.ccovm = 0.4 / (self.dim**1.6 + 1)\n",
        "\n",
        "        self.x = np.zeros(self.dim)\n",
        "        self.s = 1.0\n",
        "        self.psucc = 0.5\n",
        "        self.fhist = []\n",
        "        self.p = np.zeros(self.dim)\n",
        "        self.chol = np.eye(self.dim)\n",
        "        self.cholinv = np.eye(self.dim)\n",
        "\n",
        "    def minimize(self, h, hx, x, sigma, chol, maxeval):\n",
        "        \"\"\"Locate approximate solutions to min_{x} h(x)\n",
        "        Parameters\n",
        "        ----------\n",
        "        h : callable\n",
        "            objective\n",
        "        hx : float\n",
        "            h(x) value\n",
        "        x : ndarray (1d)\n",
        "            initial solution\n",
        "        sigma : float\n",
        "            step-size\n",
        "        chol : ndarray (2d)\n",
        "            cholesky factor\n",
        "        maxeval : int\n",
        "            maximal number of f-calls\n",
        "        Returns\n",
        "        -------\n",
        "        hz (float) : h(zt)\n",
        "        zt (ndarray, 1d) : approximate solution\n",
        "        theta (tuple) : parameters for z\n",
        "        neval (int) : number of h-calls\n",
        "        \"\"\"\n",
        "        nsucc = 0\n",
        "        neval = 0\n",
        "        self.x = np.copy(x)\n",
        "        self.s = sigma\n",
        "        self.psucc = 0.5\n",
        "        self.fhist = [hx]\n",
        "        self.p = np.zeros(self.dim)\n",
        "        self.chol = np.copy(chol)\n",
        "        self.cholinv = np.linalg.inv(self.chol)\n",
        "        self.rescale()\n",
        "        self.rescale_itr = 0\n",
        "        while nsucc < self.dim * self.tau + self.tau_offset:\n",
        "            z_, y_, x_ = self.generate()\n",
        "            hx = h(x_)\n",
        "            self.update(z_, y_, x_, hx)\n",
        "            succ = hx <= self.fhist[0]\n",
        "            nsucc += int(succ)\n",
        "            neval += 1\n",
        "            if self.rescale_itr > self.dim:\n",
        "                self.rescale()\n",
        "                self.rescale_itr = 0\n",
        "            else:\n",
        "                self.rescale_itr += 1\n",
        "            if self.verbose:\n",
        "                print(neval, hx, self.s)\n",
        "            if self.s <= self.tolsigma or hx <= self.tolh or neval >= maxeval:\n",
        "                break\n",
        "        return self.fhist[0], self.x, max(self.s, self.tolsigma), self.chol, neval\n",
        "\n",
        "    def generate(self):\n",
        "        z = np.random.randn(self.dim)\n",
        "        y = np.dot(self.chol, z)\n",
        "        x = self.x + self.s * y\n",
        "        return z, y, x\n",
        "\n",
        "    def rescale(self):\n",
        "        frob = np.sum(self.chol ** 2)\n",
        "        scale = np.sqrt(frob / self.dim)\n",
        "        self.s *= scale\n",
        "        self.chol /= scale\n",
        "        self.cholinv *= scale\n",
        "        self.p /= scale\n",
        "\n",
        "    def update(self, z, y, x, fx):\n",
        "        if fx <= self.fhist[0]:\n",
        "            self.fhist = [fx] + self.fhist[:min(4, len(self.fhist))]\n",
        "            self.x = x\n",
        "            self.s *= self.aup\n",
        "            self.psucc = (1.0 - self.cp) * self.psucc + self.cp\n",
        "            if self.psucc > self.pthresh:\n",
        "                self.p = (1.0 - self.cc) * self.p\n",
        "                d = self.ccovp * (1.0 - self.cc * (2.0 - self.cc))\n",
        "            else:\n",
        "                self.p = (1.0 - self.cc) * self.p + np.sqrt(self.cc * (2.0 - self.cc)) * y\n",
        "                d = self.ccovp\n",
        "            w = np.dot(self.cholinv, self.p)\n",
        "            wnorm2 = np.dot(w, w)\n",
        "            if wnorm2 > 1e-6:\n",
        "                a = np.sqrt(1.0 - d)\n",
        "                b = np.sqrt(1.0 - d) * (np.sqrt(1.0 + self.ccovp * wnorm2 / (1.0 - d)) - 1.0) / wnorm2\n",
        "                self.chol = a * self.chol + b * np.outer(self.p, w)\n",
        "                self.cholinv = self.cholinv / a - (b / (a**2 + a * b * wnorm2)) * np.outer(w, np.dot(w, self.cholinv))\n",
        "        else:\n",
        "            self.s *= self.adown\n",
        "            self.psucc = (1.0 - self.cp) * self.psucc\n",
        "            if len(self.fhist) > 4 and fx > self.fhist[4] and self.psucc <= self.pthresh:\n",
        "                znorm2 = np.dot(z, z)\n",
        "                ccov = self.ccovm if 1.0 >= self.ccovm * (2.0 * znorm2 - 1.0) else 1.0 / (2.0 * znorm2 - 1.0)\n",
        "                a = np.sqrt(1.0 + ccov)\n",
        "                b = np.sqrt(1.0 + ccov) * (np.sqrt(1.0 - ccov * znorm2 / (1.0 + ccov)) - 1) / znorm2\n",
        "                self.chol = a * self.chol + b * np.outer(y, z)\n",
        "                self.cholinv = self.cholinv / a - (b / (a**2 + a * b * znorm2)) * np.outer(z, np.dot(z, self.cholinv))\n",
        "\n",
        "\n",
        "class AdversarialCmaes:\n",
        "\n",
        "    def __init__(self, f, x_dim, y_dim, x_tau=5, y_tau=5, x_tau_offset=5, y_tau_offset=5, tolgap=0, aeta=1, beta=5, ceta=1.1, xsampler=None, ysampler=None, xsigma_min=0, ysigma_min=0, xlbound=None, xubound=None, ylbound=None, yubound=None, logpath=None, logchol=True):\n",
        "        \"\"\"Adversarial-CMA-ES\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        f : callable\n",
        "            objective function\n",
        "        x_dim, y_dim : int\n",
        "            dimension of x and y\n",
        "        x_tau, y_tau, x_tau_offset, y_tau_offset : int, optional\n",
        "            number of iterations of the internal (1+1)-CMA-ES is\n",
        "            x_tau * x_dim + x_tau_offset (for x) and\n",
        "            y_tau * y_dim + y_tau_offset (for y).\n",
        "        tolgap : float >= 0, optional\n",
        "            termination condition.\n",
        "            stop if the estimated suboptimality error is smaller than `tolgap`\n",
        "        aeta, beta, ceta : float, optional\n",
        "            hyper-parameters of the learning rate adaptation\n",
        "            aeta, beta : the number of oracle calls to estimate the convergence rate is aeta / eta + beta\n",
        "            ceta : learning rate is increased or decreased by the factor ceta\n",
        "        xsampler, ysampler : callable, optional\n",
        "            x and y samplers\n",
        "        tolxsigma, tolysigma : float >= 0, optional\n",
        "            minimal step-size\n",
        "        xlbound, xubound : numpy.ndarray (1d)\n",
        "            lower and upper bound of the search interval for x\n",
        "        ylbound, yubound : numpy.ndarray (1d)\n",
        "            lower and upper bound of the search interval for y\n",
        "        logpath : str, optional\n",
        "            log file name\n",
        "        logchol : bool, optional\n",
        "            write out the cholesky factor of the CMA-ES into the log file if this is true\n",
        "        \"\"\"\n",
        "        self._f = f\n",
        "        self.xsampler = xsampler\n",
        "        self.ysampler = ysampler\n",
        "        self.ysigma_min = ysigma_min\n",
        "        self.x_cma = Cmaes(x_dim, x_tau, x_tau_offset, tolsigma=xsigma_min)\n",
        "        self.y_cma = Cmaes(y_dim, y_tau, y_tau_offset, tolsigma=ysigma_min)\n",
        "        self.tolgap = tolgap\n",
        "        self.aeta = aeta\n",
        "        self.beta = beta\n",
        "        self.ceta = ceta\n",
        "        self.xlbound = xlbound\n",
        "        self.xubound = xubound\n",
        "        self.ylbound = ylbound\n",
        "        self.yubound = yubound\n",
        "        self.logpath = logpath\n",
        "        self.logchol = logchol\n",
        "        self.neval = 0\n",
        "        self.yhist = []\n",
        "\n",
        "    def f(self, x, y):\n",
        "        fxy = self._f(x, y)\n",
        "        self.neval += 1\n",
        "        return fxy\n",
        "\n",
        "    def fyhist(self, x, y, twooutput=False):\n",
        "        fxy = self.f(x, y)\n",
        "        if len(self.yhist) > 0:\n",
        "            fxyhist = np.max([self.f(x, yy) for yy in self.yhist])\n",
        "            if twooutput:\n",
        "                return max(fxyhist, fxy), fxy\n",
        "            else:\n",
        "                return max(fxyhist, fxy)\n",
        "        else:\n",
        "            if twooutput:\n",
        "                return fxy, fxy\n",
        "            else:\n",
        "                return fxy\n",
        "\n",
        "    def optimize_with(self, eta, x0, y0, xsigma0, ysigma0, xchol0, ychol0, nstep, maxeval, minitr):\n",
        "        \"\"\"Adversarial-CMA-ES with Fixed Learning Rate\n",
        "        Parameters\n",
        "        ----------\n",
        "        eta : float\n",
        "            learning rate\n",
        "        x0, y0 : ndarray (1d)\n",
        "            initial x and x\n",
        "        xsigma0, ysigma0 : float\n",
        "            initial step-size\n",
        "        xchol0, ychol0 : ndarray (2d)\n",
        "            initial cholesky factor\n",
        "        nstep : int\n",
        "            maximum iterations\n",
        "        maxeval : int\n",
        "            maximum number of f-calls\n",
        "        minitr : int\n",
        "            minimum iterations\n",
        "        Returns\n",
        "        -------\n",
        "        x (ndarray, 1D) : solution\n",
        "        y (ndarray, 1D) : solution\n",
        "        gap (ndarray, 1D) : history of gap: f(x', yt) - f(xt, y')\n",
        "        \"\"\"\n",
        "\n",
        "        x = np.copy(x0)\n",
        "        y = np.copy(y0)\n",
        "        xp = np.copy(x)\n",
        "        yp = np.copy(y)\n",
        "        x_sigma = xsigma0\n",
        "        y_sigma = ysigma0\n",
        "        x_chol = np.copy(xchol0)\n",
        "        y_chol = np.copy(ychol0)\n",
        "        dim_theta_x = 1 + len(x) ** 2 if self.logchol else 1\n",
        "        dim_theta_y = 1 + len(y) ** 2 if self.logchol else 1\n",
        "        res = np.zeros(1+1+1+1+len(x)+len(y)+dim_theta_x+dim_theta_y)\n",
        "        gap_array = np.zeros(nstep)\n",
        "\n",
        "        for i in range(nstep):\n",
        "            # Determine whether or not to start from x or xp (y or yp)\n",
        "            fxyhist, fxy = self.fyhist(x, y, twooutput=True)\n",
        "            fxpy = self.fyhist(xp, y)\n",
        "            fxyp = self.f(x, yp)\n",
        "            if fxpy > fxyhist:\n",
        "                xp[:] = x[:]\n",
        "                fxpy = fxyhist\n",
        "                x_sigma = xsigma0\n",
        "                x_chol = np.copy(xchol0)\n",
        "            if fxyp < fxy:\n",
        "                yp[:] = y[:]\n",
        "                fxyp = fxy\n",
        "                y_sigma = ysigma0\n",
        "                y_chol = np.copy(ychol0)\n",
        "\n",
        "            # Adversarial steps\n",
        "            fx, xp, x_sigma, x_chol, nx = self.x_cma.minimize(lambda z:  self.fyhist(z, y), fxpy, xp, x_sigma, x_chol, maxeval - self.neval)\n",
        "            fy, yp, y_sigma, y_chol, ny = self.y_cma.minimize(lambda z:  -self.f(x, z), -fxyp, yp, y_sigma, y_chol, maxeval - self.neval)\n",
        "            fy = -fy\n",
        "\n",
        "            # Mirror solutions if the domain is bounded\n",
        "            if self.xlbound is not None:\n",
        "                xp = mirror(xp, self.xlbound, self.xubound)\n",
        "            if self.ylbound is not None:\n",
        "                yp = mirror(yp, self.ylbound, self.yubound)\n",
        "\n",
        "            # Try random samples\n",
        "            if self.xsampler is not None:\n",
        "                xtrial = self.xsampler()\n",
        "                fxytrial = self.fyhist(xtrial, y)\n",
        "                nx += 1\n",
        "                if fxytrial < fx:\n",
        "                    xp = xtrial\n",
        "                    fx = fxytrial\n",
        "            if self.ysampler is not None:\n",
        "                ytrial = self.ysampler()\n",
        "                fxytrial = self.f(x, ytrial)\n",
        "                ny += 1\n",
        "                if fxytrial > fy:\n",
        "                    if fy >= fxyhist:\n",
        "                        self.register(yp)\n",
        "                    yp = ytrial\n",
        "                    fy = fxytrial\n",
        "\n",
        "            # Estimated Suboptimality Error\n",
        "            gap = max(fxyhist, fy) - fx\n",
        "\n",
        "            # Update\n",
        "            x += eta * (xp - x)\n",
        "            y += eta * (yp - y)\n",
        "\n",
        "            # Output\n",
        "            idx = 0\n",
        "            res[idx] = self.neval; idx += 1\n",
        "            res[idx] = fxyhist; idx += 1\n",
        "            res[idx] = gap; idx += 1\n",
        "            res[idx] = eta; idx += 1\n",
        "            res[idx:idx+len(x)] = x; idx += len(x)\n",
        "            res[idx:idx+len(y)] = y; idx += len(y)\n",
        "            res[idx] = x_sigma; idx += 1\n",
        "            if self.logchol:\n",
        "                res[idx:idx+dim_theta_x-1] = x_chol.flatten(); idx += dim_theta_x - 1\n",
        "            res[idx] = y_sigma; idx += 1\n",
        "            if self.logchol:\n",
        "                res[idx:idx+dim_theta_x-1] = y_chol.flatten(); idx += dim_theta_y - 1\n",
        "            with open(self.logpath, 'ba') as flog:\n",
        "                np.savetxt(flog, res, newline=' ')\n",
        "                flog.write(b\"\\n\")\n",
        "\n",
        "            # Termination condition\n",
        "            gap_array[i] = gap\n",
        "            if self.neval >= maxeval:\n",
        "                break\n",
        "            if gap_array[i] < self.tolgap:\n",
        "                break\n",
        "            if i >= minitr - 1:\n",
        "                gap = gap_array[i+1-minitr:i+1]\n",
        "                if minitr > 1 and np.all(gap[1:minitr] - gap[0:minitr-1] > 0):\n",
        "                    break\n",
        "        return x, y, gap_array[:i+1]\n",
        "\n",
        "\n",
        "    def optimize(self, etamin, x0, y0, xsigma0, ysigma0, xchol0, ychol0, maxeval):\n",
        "        \"\"\"Adversarial Evolution Strategy with Learning Rate Adaptation\n",
        "        Parameters\n",
        "        ----------\n",
        "        etamin : float\n",
        "            minimal learning rate\n",
        "        x0, y0 : ndarray (1d)\n",
        "            initial x and x\n",
        "        xsigma0, ysigma0 : float\n",
        "            initial step-size\n",
        "        xchol0, ychol0 : ndarray (2d)\n",
        "            initial cholesky factor\n",
        "        maxeval : int\n",
        "            maximum number of f-calls\n",
        "        Returns\n",
        "        -------\n",
        "        x (ndarray, 1D) : solution\n",
        "        y (ndarray, 1D) : solution\n",
        "        \"\"\"\n",
        "        x = np.copy(x0)\n",
        "        y = np.copy(y0)\n",
        "        x_sigma = xsigma0\n",
        "        y_sigma = ysigma0\n",
        "        x_chol = np.copy(xchol0)\n",
        "        y_chol = np.copy(ychol0)\n",
        "        eta = 1.0\n",
        "        slp = 0.0\n",
        "        while self.neval < maxeval:\n",
        "            u = np.random.rand()\n",
        "            if u < 1/3:\n",
        "                eta1 = eta * self.ceta\n",
        "            elif 1/3 <= u < 2/3:\n",
        "                eta1 = eta\n",
        "            else:\n",
        "                eta1 = eta / self.ceta\n",
        "            eta1 = np.clip(eta1, etamin, 1)\n",
        "            nstep = self.beta + int(self.aeta/eta1)\n",
        "            x1, y1, gap = self.optimize_with(eta1, x, y, x_sigma, y_sigma, x_chol, y_chol, nstep, maxeval, self.beta)\n",
        "            if gap[-1] < self.tolgap or self.neval >= maxeval:\n",
        "                break\n",
        "            xarr = np.arange(len(gap))\n",
        "            slp1, _, _, _, std1 = stats.linregress(xarr, np.log(np.fmax(gap, self.tolgap)))\n",
        "            if slp1 - 2*std1 < 0:\n",
        "                x = x1\n",
        "                y = y1\n",
        "                x_sigma = self.x_cma.s\n",
        "                y_sigma = self.y_cma.s\n",
        "                x_chol = self.x_cma.chol\n",
        "                y_chol = self.y_cma.chol\n",
        "            if slp >= 0 and slp1 >= 0:\n",
        "                eta = np.clip(eta / self.ceta**3, etamin, 1)\n",
        "                slp = 0.0\n",
        "            elif slp1 <= slp:\n",
        "                eta = eta1\n",
        "                slp = slp1\n",
        "            elif eta == eta1:\n",
        "                slp = slp1\n",
        "        return x1, y1\n",
        "\n",
        "    def register(self, yp):\n",
        "        if len(self.yhist) > 0:\n",
        "            dist = np.asarray([np.linalg.norm(yh - yp) for yh in self.yhist])\n",
        "            if np.min(dist) > self.ysigma_min * np.sqrt(len(yp)):\n",
        "                self.yhist += [np.copy(yp)]\n",
        "        else:\n",
        "            self.yhist += [np.copy(yp)]\n",
        "\n",
        "\n",
        "def mirror(z, lbound, ubound):\n",
        "    width = ubound - lbound\n",
        "    return ubound - np.abs(np.mod(z - lbound, 2 * width) - width)\n",
        "\n",
        "\n",
        "def generate_cmaes_parameter(lbound, ubound):\n",
        "    dim = len(lbound)\n",
        "    x = lbound + (ubound - lbound) * np.random.rand(dim)\n",
        "    sigma = 1.0\n",
        "    chol = np.diag( (ubound - lbound) / 4. )\n",
        "    return x, sigma, chol\n",
        "\n",
        "\n",
        "def minmax(f, xlbound, xubound, ylbound, yubound, maxeval, bounded, etamin=1e-4, tolgap=1e-6, tolxsigma=1e-8, tolysigma=1e-8, logpath=\"advcma.csv\", logchol=True, initx=None, initxsigma=None, inity=None, initysigma=None):\n",
        "    \"\"\"Optimize min-max problem f with Adversarial-CMA-ES with restart\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    f : callable\n",
        "        min-max objective function f(x, y)\n",
        "    xlbound, xubound : numpy.ndarray (1d)\n",
        "        lower and upper bound of the initialization interval for x\n",
        "    ylbound, yubound : numpy.ndarray (1d)\n",
        "        lower and upper bound of the initialization interval for y\n",
        "    maxeval : int\n",
        "        maximum number of f-calls\n",
        "    bounded : bool\n",
        "        the domain is bounded (== initialization interval) if it is True\n",
        "    etamin : float >= 0, optional\n",
        "        minimal accepted learning rate\n",
        "    tolgap : float >= 0, optional\n",
        "        restart is performed if the suboptimality error reach this tolerance value\n",
        "    tolxsigma, tolysigma : float >= 0, optional\n",
        "        minimal step-size\n",
        "    logpath : str, optional\n",
        "        log file name\n",
        "    logchol : bool, optional\n",
        "        write out the cholesky factor of the CMA-ES into the log file if this is true\n",
        "    initx, inity : numpy.ndarray (1d), optional\n",
        "        initial guess\n",
        "    initxsigma, initysigma : float > 0, optional\n",
        "        initial step size, valid only when initx and inity are given\n",
        "    Returns\n",
        "    -------\n",
        "    float : f(x, y) value\n",
        "    numpy.ndarray (1d) : x best\n",
        "    numpy.ndarray (1d) : y worst\n",
        "    numpy.ndarray (2d) : f(x_i, y_j)\n",
        "    list of numpy.ndarray (1d) : list of candidate x\n",
        "    list of numpy.ndarray (1d) : list of candidate y\n",
        "    \"\"\"\n",
        "\n",
        "    def xsampler():\n",
        "        return xlbound + (xubound - xlbound) * np.random.rand(len(xlbound))\n",
        "    def ysampler():\n",
        "        return ylbound + (yubound - ylbound) * np.random.rand(len(ylbound))\n",
        "    xhist = []\n",
        "    if bounded:\n",
        "        xl, xu, yl, yu = xlbound, xubound, ylbound, yubound\n",
        "        def ff(x, y):\n",
        "            xmirror = mirror(x, xlbound, xubound)\n",
        "            ymirror = mirror(y, ylbound, yubound)\n",
        "            return f(xmirror, ymirror)\n",
        "    else:\n",
        "        xl, xu, yl, yu = None, None, None, None\n",
        "        ff = f\n",
        "    advcma = AdversarialCmaes(ff, len(xlbound), len(ylbound), tolgap=tolgap, xsampler=xsampler, ysampler=ysampler, xlbound=xl, xubound=xu, ylbound=yl, yubound=yu, xsigma_min=tolxsigma, ysigma_min=tolysigma, logpath=logpath, logchol=logchol)\n",
        "    while advcma.neval < maxeval:\n",
        "        x0, xsigma0, xchol0 = generate_cmaes_parameter(xlbound, xubound)\n",
        "        if len(xhist) == 0:\n",
        "            if initx is not None:\n",
        "                x0 = np.array(initx, copy=True)\n",
        "                if initxsigma is not None:\n",
        "                    xsigma0 = initxsigma\n",
        "        y0, ysigma0, ychol0 = generate_cmaes_parameter(ylbound, yubound)\n",
        "        if len(xhist) == 0:\n",
        "            if inity is not None:\n",
        "                y0 = np.array(inity, copy=True)\n",
        "                if initysigma is not None:\n",
        "                    ysigma0 = initysigma\n",
        "        x, y = advcma.optimize(etamin, x0, y0, xsigma0, ysigma0, xchol0, ychol0, maxeval)\n",
        "        xhist += [x]\n",
        "        advcma.register(y)\n",
        "    yhist = advcma.yhist\n",
        "    f_arr = np.zeros((len(xhist), len(yhist)))\n",
        "    for i, x in enumerate(xhist):\n",
        "        for j, y in enumerate(yhist):\n",
        "            f_arr[i, j] = f(x, y)\n",
        "    xidx = np.argmin(np.max(f_arr, axis=1))\n",
        "    yidx = np.argmax(f_arr[xidx])\n",
        "    return f_arr[xidx, yidx], xhist[xidx], yhist[yidx], f_arr, xhist, yhist\n",
        "\n",
        "\n",
        "def minimize(f, lbound, ubound, bounded, maxeval, totalmaxeval, tolsigma=1e-8, tolf=-np.inf):\n",
        "    \"\"\"Locate approximate solutions to min_{x} f(x)\n",
        "    Parameters\n",
        "    ----------\n",
        "    f : callable\n",
        "        objective\n",
        "    lbound, ubound : numpy.ndarray (1d)\n",
        "        lower and upper bound of the initialization interval for x\n",
        "    bounded : bool\n",
        "        the domain is bounded (== initialization interval) if it is True\n",
        "    maxeval : int\n",
        "        maximal number of f-calls for each (1+1)-CMA-ES run\n",
        "    totalmaxeval : int\n",
        "        maximal number of f-calls for restart\n",
        "    tolxigma : float >= 0, optional\n",
        "        minimal step-size\n",
        "    tolf : float, optional\n",
        "        minimal objective value\n",
        "    Returns\n",
        "    -------\n",
        "    float : best f(x) value\n",
        "    numpy.ndarray (1d) : best x\n",
        "    numpy.ndarray (1d) : list of f(x)\n",
        "    numpy.ndarray (2d) : list of x\n",
        "    \"\"\"\n",
        "\n",
        "    if bounded:\n",
        "        def h(z):\n",
        "            zmirror = mirror(z, lbound, ubound)\n",
        "            return f(zmirror)\n",
        "    else:\n",
        "        def h(z):\n",
        "            return f(z)\n",
        "    f_arr = []\n",
        "    z_arr = []\n",
        "    nfev = 0\n",
        "    while nfev < totalmaxeval:\n",
        "        z, sigma, chol = generate_cmaes_parameter(lbound, ubound)\n",
        "        cma = Cmaes(len(z), tau=0, tau_offset=maxeval, tolsigma=tolsigma, tolh=tolf)\n",
        "        hz, z, _, _, neval = cma.minimize(h, h(z), z, sigma, chol, min(maxeval, totalmaxeval - nfev - 1))\n",
        "        nfev += neval + 1\n",
        "        f_arr += [hz]\n",
        "        z_arr += [mirror(z, lbound, ubound) if bounded else z]\n",
        "    zidx = np.argmin(f_arr)\n",
        "    return f_arr[zidx], z_arr[zidx], f_arr, z_arr\n",
        "\n",
        "\n",
        "def worstsearch(f, x, ylbound, yubound, bounded, maxeval, tolsigma=1e-8, n_restart=100, inity=None, initysigma=None):\n",
        "    \"\"\"Worst case search by the (1+1)-CMA-ES\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    f : callable\n",
        "        min-max objective function\n",
        "    x : numpy.ndarray (1d)\n",
        "        x to be evaluated\n",
        "    ylbound, yubound : numpy.ndarray (1d)\n",
        "        lower and upper bound of the initialization interval for y\n",
        "    maxeval : int\n",
        "        maximum number of f-calls for each restart\n",
        "    tolsigma : float >= 0, optional\n",
        "        minimal step-size\n",
        "    n_restart : int >= 1, optional\n",
        "        number of restart\n",
        "    inity : numpy.ndarray (1d), optional\n",
        "        initial solution\n",
        "    initysigma : float > 0, optional\n",
        "        initial step-size, valid only when inity is given\n",
        "    Returns\n",
        "    -------\n",
        "    float : worst f(x, y) value\n",
        "    numpy.ndarray (1d) : worst y\n",
        "    numpy.ndarray (1d) : f(x, y_j)\n",
        "    numpy.ndarray (2d) : list of candidate y\n",
        "    \"\"\"\n",
        "    if bounded:\n",
        "        def h(y):\n",
        "            ymirror = mirror(y, ylbound, yubound)\n",
        "            return -f(x, ymirror)\n",
        "    else:\n",
        "        def h(y):\n",
        "            return -f(x, y)\n",
        "    f_arr = np.zeros(n_restart)\n",
        "    y_arr = np.zeros((n_restart, len(ylbound)))\n",
        "    for i in range(n_restart):\n",
        "        y, sigma, chol = generate_cmaes_parameter(ylbound, yubound)\n",
        "        if i == 0:\n",
        "            if inity is not None:\n",
        "                y = np.array(inity)\n",
        "                if initysigma is not None:\n",
        "                    sigma = initysigma\n",
        "        cma = Cmaes(len(y), tau=0, tau_offset=maxeval, tolsigma=tolsigma)\n",
        "        hy, y, _, _, _ = cma.minimize(h, h(y), y, sigma, chol, maxeval)\n",
        "        f_arr[i] = -hy\n",
        "        y_arr[i] = mirror(y, ylbound, yubound) if bounded else y\n",
        "    yidx = np.argmax(f_arr)\n",
        "    return f_arr[yidx], y_arr[yidx], f_arr, y_arr\n",
        "\n"
      ],
      "metadata": {
        "id": "1HiXEJeBP17f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 実行スクリプト\n",
        "以下では，前節においてナイーブなアプローチを評価した際と同じ目的関数に対し，Adversarial-CMA-ESを適用している．\n"
      ],
      "metadata": {
        "id": "fCjlOr8vWT8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 簡単のため， x と y の次元数は等しいとする．\n",
        "N = 10\n",
        "a = c = 1.0\n",
        "b = 10.0\n",
        "\n",
        "def f(x, y):\n",
        "    return a * np.dot(x, x) + b * np.dot(x, y) - c * np.dot(y, y)\n",
        "\n",
        "def f_worst(x):\n",
        "    y = b * x / 2 / c\n",
        "    return f(x, y)\n",
        "\n",
        "np.random.seed(100)\n",
        "m = n = 10\n",
        "a = 1\n",
        "b = 4\n",
        "c = 1\n",
        "bounded = False\n",
        "# Initialization Interval\n",
        "xlbound = -np.ones(m)\n",
        "xubound = np.ones(m)\n",
        "ylbound = -np.ones(n)\n",
        "yubound = np.ones(n)\n",
        "# Optimization\n",
        "maxeval = 1e5\n",
        "logpre = 'advcma_ftest'\n",
        "logpath = logpre + '.csv'\n",
        "logpathx = logpre + '_x.csv'\n",
        "logpathy = logpre + '_y.csv'\n",
        "logpathworst = logpre + '_worst_y.csv'\n",
        "try:\n",
        "    os.remove(logpath)\n",
        "    os.remove(logpathx)\n",
        "    os.remove(logpathy)\n",
        "    os.remove(logpathworst)\n",
        "except:\n",
        "    pass\n",
        "print(\"Optimization has started.\")\n",
        "fxy, xbest, yworst, f_arr, x_arr, y_arr = minmax(f, xlbound, xubound, ylbound, yubound, maxeval, bounded, etamin=1e-4, tolgap=1e-6, tolxsigma=1e-8, tolysigma=1e-8, logpath=logpath, logchol=False)\n",
        "print(\"Optimization has finished.\")\n",
        "print(\"best x:\", xbest)\n",
        "print(\"worst y:\", yworst)\n",
        "print(\"f(x,y):\", fxy)\n",
        "print(f_arr)\n",
        "np.savetxt(logpathx, x_arr)\n",
        "np.savetxt(logpathy, y_arr)\n",
        "# Evaluation\n",
        "print(\"Worst-case search has started.\")\n",
        "fy, y, f_arr, y_arr = worstsearch(f, xbest, ylbound, yubound, bounded, maxeval=100*len(ylbound), tolsigma=1e-8, n_restart=100)\n",
        "print(\"Worst-case search has finished.\")\n",
        "print(\"worst y:\", y)\n",
        "print(\"f(x,y):\", fy)\n",
        "print(f_arr)\n",
        "np.savetxt(logpathworst, y_arr)\n",
        "# Plot\n",
        "dat = np.loadtxt(logpath)\n",
        "fig = plt.figure()\n",
        "plt.semilogy(dat[:, 0], dat[:, 2], label=\"max_y f(x, y) - min_x f(x, y) (estimated)\")\n",
        "plt.semilogy(dat[:, 0], dat[:, 3], label=\"eta\")\n",
        "plt.semilogy(dat[:, 0], dat[:, -2], label=\"sigma_x\")\n",
        "plt.semilogy(dat[:, 0], dat[:, -1], label=\"sigma_y\")\n",
        "plt.grid()\n",
        "plt.xlabel(\"#f-calls\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"advcma_ftest.pdf\")"
      ],
      "metadata": {
        "id": "uHhnsTqQTyTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ミニマックス最適化によって得られた最適解が xbest，その際の最悪シナリオが yworst，その目的関数値（すなわち推定された最悪性能$f(xbest, yworst)$）がfxyである．\n",
        "その後，ワーストケース探索を行って得られた最悪シナリオが y，その目的関数値がfy である．\n",
        "今回の場合，真の最悪性能が既知であるためこれを計算すると， fy と非常に近い値になっていることが確認できる．\n",
        "真の最悪性能の最小値は 0 であるため，最適解近傍の解が得られていることが確認できる．"
      ],
      "metadata": {
        "id": "t-VNFnhMYCXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('ミニマックス最適化により得られた x', xbest)\n",
        "print('ミニマックス最適化により得られた y', yworst)\n",
        "print('ミニマックス最適化により得られた f(x, y)', fxy)\n",
        "print('ワーストケース探索により得られた y', y)\n",
        "print('ワーストケース探索により得られた f(x, y)', fy)\n",
        "print('真の最悪性能 max_y f(x, y)', f_worst(xbest))"
      ],
      "metadata": {
        "id": "4B2jNcr0Upbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WRA-CMA-ES\n",
        "WRA-CMA-ESはAdversarial-CMA-ESと異なり，直接的に最悪性能\n",
        "$$\n",
        "F_Y(x) = \\max_{y \\in Y} f(x, y)\n",
        "$$\n",
        "を近似し，これをCMA-ESを用いて最小化することを目指す方法である．\n",
        "\n",
        "WRA-CMA-ESはAdversarial-CMA-ESの以下の弱点の解決を目指した方法である:\n",
        "\n",
        "* $f$ が smooth で strongly convex-concave でない場合，ミニマックス最適解に収束しない場合がある．\n",
        "\n",
        "* $x$ と $y$ のインタラクションが強い場合（上の凹凸二次関数の場合，$b$が大きい場合）に収束速度が著しく遅くなる（交互最適化を実行する場合，厳密な最適解が得られるとしても最適な$\\eta$のもとで収束の速さが$b$に依存する）\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3WbqetOQbwas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Worst-case Ranking Approximation\n",
        "\n",
        "$F_Y(x)$をCMA-ESを用いて最適化しようとした場合，各イテレーションにおいて生成された解$x_1, \\dots, x_\\lambda$の最悪性能$F_Y(x_i)$のランキングを計算する必要がある．\n",
        "そのためには，$F_Y(x_i)$の真の値を知る必要があるが，$f$がブラックボックスであることから，これは知り得ない．\n",
        "\n",
        "各$x_i$に対して，$\\max_{y \\in Y} f(x, y)$を数値的に解くことにより，最悪性能を近似する方針が考えられる．\n",
        "ただし，\n"
      ],
      "metadata": {
        "id": "PgdRZrfvecnI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HG3yAzF4b5nB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
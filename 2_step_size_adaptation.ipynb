{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akimotolab/CMAES_Tutorial/blob/main/2_step_size_adaptation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzwB6CNoO4ov"
      },
      "source": [
        "# Step-Size Adaptation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFRswkUYO4ow"
      },
      "source": [
        "前回までに，Sphere関数において，以下を実験的に確認した．\n",
        "1. 平均ベクトルと最適解の距離と比較して，ステップサイズと次元数の積が非常に小さい場合，指数スケールで見た場合に目的関数の減少率が低い．（指数スケールでなく，目的関数の値の減少量に着目した場合は，3.の場合と同程度かそれ以上に大きいことに注意．ここではあくまで減少率に着目している）\n",
        "2. 平均ベクトルと最適解の距離と比較して，ステップサイズと次元数の積が非常に大きい場合，探索が停滞する\n",
        "3. 平均ベクトルと最適解の距離と比較して，ステップサイズと次元数の積が同程度の場合，指数スケールで見た場合に目的関数の減少率が高い\n",
        "\n",
        "上述のような振る舞いをする理由は以下の通りである．\n",
        "\n",
        "1. $\\|m - x^*\\| \\gg \\sigma$ の場合：平均ベクトルの更新は，生成された解のうち上位$\\mu$個の平均値を取ることで行われる．生成される解は$m$を中心に，$\\sigma \\mathcal{N}(0, I)$を加えることで生成されるわけだが，$\\|\\mathcal{N}(0, 1)\\|$は自由度$N$（$N$は次元数）の$\\chi$分布に従うため，その期待値は$\\sqrt{N}$程度である．したがって，一度の$m$の更新での変化量（距離）は高々$\\sigma \\sqrt{N}$程度である．このとき，更新前の平均ベクトル$m$と更新後の平均ベクトル$m'$とで，最適解からの距離を考えると，\n",
        "$$\n",
        "\\frac{\\| m' - x^* \\|}{\\| m - x^* \\|} \\gtrapprox \\frac{\\| m - x^* \\| - \\alpha \\sigma \\sqrt{N}}{\\| m - x^* \\|} = 1 - \\frac{\\alpha \\sigma \\sqrt{N}}{\\| m - x^* \\|}\n",
        "$$\n",
        "となることが予想される．ここで，$\\alpha > 0$は何らかの比例定数である．$\\|m - x^*\\| \\gg \\sigma$である場合には，第２項が$0$に近いため，平均ベクトルと最適解の距離が，比率の意味ではほとんど減少していかないように見えるのである．ただ，変化量自体は$\\sigma \\sqrt{N}$に比例しているため，最適解にコンスタントに近づいてはいる．\n",
        "\n",
        "2. $\\|m - x^*\\| \\ll \\sigma$ の場合：簡単のため，$m = x^*$である場合を考える．このとき，解候補は$x_i \\sim \\sigma \\mathcal{N}(0, I)$に従って生成される．この中から上位$\\mu$個を選択してその平均を計算しているが，理解のため，ランダムに選択された$\\mu$個の解の平均を計算すると，これは正規分布の性質から\n",
        "$$\n",
        "\\sum_{i=1}^{\\mu} w_i x_i \\sim \\mathcal{N}\\left( 0, \\left(\\sum_{i=1}^{\\mu} w_i^2\\right)\\sigma^2 I \\right) \\sim \\frac{\\sigma }{\\sqrt{\\mu}}\\mathcal{N}\\left( 0, I \\right)\n",
        "$$\n",
        "となる．これが更新後の平均ベクトル$m'$が従う確率分布となる．すなわち，$m = x^*$であったとしても，更新後には$\\sigma \\sqrt{N} / \\sqrt{\\mu}$ に比例した距離だけ最適解から離れることが予想される．この議論では簡単のため上位解がランダムに選択されていることを想定したが，本来は最適解により近い解が選択されているため，ここで計算した分布よりも最適解に近い分布に従うことが予想される．ただし，解を正規分布から生成しており，正規分布のノルムの値が期待値付近に集中しているという事実を考えれば，ここで考えた分布とそう変わらないことが予想される．したがって，$\\sigma$の大きさによって定まる距離以上に最適解に収束していくことはできないことが分かる．\n",
        "\n",
        "3. $\\| m - x^*\\| \\propto N \\sigma$ の場合：1. での議論から，$\\sigma \\propto \\| m - x^*\\|$のとき，指数的に平均ベクトルが最適解に近づいていくことがわかる．なぜ$\\| m - x^*\\| \\propto N \\sigma$が適切なのか（なぜ$N$に比例するのか）は簡単に説明することは難しい．ただ，凸二次関数の場合，一回の平均ベクトル更新で目的関数の期待値を最も減少させるためには，$\\sigma \\propto \\|\\nabla f\\| / Tr(\\nabla \\nabla f)$ であることが解析的に求められており[1,2]，Sphere関数の場合には，\n",
        "$$\n",
        "\\sigma \\propto \\frac{\\|\\nabla f\\|}{Tr(\\nabla \\nabla f)} = \\frac{\\| m - x^*\\|}{N}\n",
        "$$\n",
        "である．\n",
        "\n",
        "#### 参考文献\n",
        "1. D. Arnold. Optimal Weighted Recombination. FOGA (2005)\n",
        "\n",
        "2. Y. Akimoto, A. Auger, N. Hansen. Quality gain analysis of the weighted recombination evolution strategy on general convex quadratic functions. TCS (2020)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 凸二次関数のもとでの最適ステップサイズ"
      ],
      "metadata": {
        "id": "wP3duuNAV3qh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上述のように，文献[1]ではSphericalな関数$h(x) = \\frac{1}{2}(x-x^*)^\\mathrm{T} (x-x^*)$，文献[2]では一般の凸二次関数$h(x) = \\frac{1}{2}(x-x^*)^\\mathrm{T} A (x-x^*)$の単調変換$g: \\mathbb{R} \\to \\mathbb{R}$によって目的関数$f(x) = g(h(x))$が与えられる場合の，最適なステップサイズを導出している．\n",
        "\n",
        "これらの文献では，指標としてパラメータ更新後の平均ベクトル$m'$における目的関数値の期待値のパラメータ更新前の平均ベクトル$m$での目的関数値からの減少率（を正規化したもの）\n",
        "$$\n",
        " \\frac{N(f(m) - \\mathbb{E}[f(m') \\mid m, \\sigma])}{f(m)}\n",
        "$$\n",
        "を採用し，これが最大になるような$\\sigma$ を次元数の極限$N\\to\\infty$のもとで導出している．これが，上述の最適ステップサイズである．\n",
        "\n",
        "Sphericalな関数の場合，最適ステップサイズは現在の平均ベクトルと最適解の距離を次元数$N$で割った値に比例する．この最適ステップサイズは$N\\to\\infty$の極限において導出されているが，有限の$N$の場合にも最適な値を良く近似している．\n",
        "\n",
        "#### 補足：ステップサイズが$N$に反比例することに対する良くある誤解\n",
        "\n",
        "良くある誤解として，Sphere関数のもとでの最適ステップサイズは\n",
        "$$\n",
        "\\frac{\\|m - x^*\\|}{\\sqrt{N}}\n",
        "$$\n",
        "に比例するのではないか，というものがある．すなわち，$N$に反比例するのではなく，＄\\sqrt{N}＄に反比例するのではないか，というものである．この$\\sqrt{N}$の理屈は以下のようである．まず，現在の平均ベクトルから最適解までの距離が$\\|m - x^*\\|$なのだから，平均ベクトルから生成される解候補までの距離もこれと同程度であるべきであると考えられるかもしれない．解候補は$x \\sim m + \\sigma \\mathcal{N}(0, I)$と生成され，$\\|x - m\\| = \\sigma \\|\\mathcal{N}(0, I)\\|$が得られる．$\\|\\mathcal{N}(0, I)\\|$は自由度$N$のχ分布に従うため，その値は$\\sqrt{N}$あたりに集中している．すなわち，$\\|x - m\\| \\approx \\sigma \\sqrt{N}$となる．これが，$\\|m - x^*\\|$と一致するには，$\\sigma = \\frac{\\|m - x^*\\|}{\\sqrt{N}}$とすればよい．概ねこういった理屈であろう．この議論自体は受け入れやすいかもしれないが，これは大きな誤解である．\n",
        "\n",
        "なぜ$\\sqrt{N}$ではなく$N$に反比例するのかの理解の助けとなるよう，厳密性を欠いた話をする．きちんと理解したい人は，文献[2]を精読いただきたい．まず，重要な点は，目的関数値の分布である．まず，アルゴリズムの回転不変性と平行移動不変性により，一般性を失うことなく最適解は$x^* = 0$，平均ベクトルは$m = (m_1, 0, \\dots, 0)$と仮定する．第一成分が最適解方向，それ以外は最適解方向に直交する方向を意味する．解候補は$x = m + \\sigma z$（$z \\sim N(0, I)$）であり，$e_1 = (1, 0, \\dots, 0)$とし，$z_\\bot = z - z_1 e_1$（最適解方向に直交する成分）とかけば，解候補を$x = m + \\sigma z_1 e_1 + \\sigma z_{\\bot}$と表すことができる．解候補の目的関数値は，\n",
        "$$\\begin{aligned}\n",
        "f(x) &= f(m) + \\sigma m^\\mathrm{T} z + \\frac{\\sigma^2}{2} z^\\mathrm{T}z \\\\\n",
        "&= f(m) + \\sigma m_1 z_1 + \\frac{\\sigma^2}{2} z^\\mathrm{T}z\n",
        "\\end{aligned}\n",
        "$$\n",
        "となる．両辺から$f(m)$を引き，$N$でわると\n",
        "$$\\begin{aligned}\n",
        "\\frac{f(x) - f(m)}{N} = \\frac{\\sigma \\|m - x^*\\| z_1}{N} + \\frac{\\sigma^2}{2} \\frac{z^\\mathrm{T}z}{N}\n",
        "\\end{aligned}\n",
        "$$\n",
        "となる．ここで，$z\\sim N(0, I)$であることから，右辺第二項$\\frac{z^\\mathrm{T}z}{N}$の期待値は$1$，標準偏差は$1/\\sqrt{N}$となる．他方，第一項の$z_1$は標準正規分布に従うため，その標準偏差は$1$である．仮に$\\sigma \\in O(\\|m - x^*\\| / N)$ならば，第二項は第一項よりも$1/\\sqrt{N}$倍程度小さな標準偏差を持つことになる．すなわち，$\\lambda$個の解候補のなかで良いと判断される解は，平均ベクトルよりも最適解方向にある解となる．一方，$\\sigma \\in \\Omega(\\|m - x^*\\| / \\sqrt{N})$の場合，第二項の標準偏差が第一項の標準偏差と同程度以上となってしまい，ランキングの良い解は最適解方向とは無関係に$\\|z\\|$が小さく生成された解となってしまう．以上より，$N$に反比例させることの必要性は，解候補のランキングを計算する際に，ノイズの大きさの影響（第二項）よりも最適解方向の影響（第一項）を考慮するためと考えられよう．"
      ],
      "metadata": {
        "id": "-A1_mZWaWAFu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE4cgRsZO4ow"
      },
      "source": [
        "## 最適ステップサイズを用いた場合の振る舞い"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpviKSfFO4ox"
      },
      "source": [
        "最適ステップサイズは特定の目的関数で，かつ勾配を知っている場合にしか計算できないため，一般的にはこれを用いたアルゴリズムは実用的ではないが，これが分かる場合（理想的な場合）の振る舞いを見ておこう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BA45meRZO4ox"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tPX-GHSQO4ox"
      },
      "outputs": [],
      "source": [
        "class OptimalES(object):\n",
        "    \"\"\"ステップサイズを最適解からの距離に比例させた Evolution Strategy\"\"\"\n",
        "\n",
        "    def __init__(self, func, init_mean, sigma_coeff, nsample):\n",
        "        \"\"\"コンストラクタ\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        func : callable\n",
        "            目的関数 (最小化)\n",
        "        init_mean : ndarray (1D)\n",
        "            初期平均ベクトル\n",
        "        sigma_coeff : float\n",
        "            ステップサイズの比例定数\n",
        "        nsample : int\n",
        "            サンプル数\n",
        "        \"\"\"\n",
        "        self.func = func\n",
        "        self.mean = init_mean.copy()\n",
        "        self.sigma_coeff = sigma_coeff\n",
        "        self.N = self.mean.shape[0]                     # 探索空間の次元数\n",
        "        self.arx = np.zeros((nsample, self.N)) * np.nan # 候補解\n",
        "        self.arf = np.zeros(nsample) * np.nan           # 候補解の評価値\n",
        "        self.sigma = self.sigma_coeff * np.linalg.norm(self.mean) / self.N\n",
        "\n",
        "        self.weights = np.zeros(nsample)\n",
        "        self.weights[:nsample//4] = 1.0 / (nsample//4)  # 重み．総和が1\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"候補解を生成する．\"\"\"\n",
        "        self.arx = self.mean + self.sigma * np.random.normal(size=self.arx.shape)\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"候補解を評価する．\"\"\"\n",
        "        for i in range(self.arf.shape[0]):\n",
        "            self.arf[i] = self.func(self.arx[i])\n",
        "\n",
        "    def update_mean(self):\n",
        "        \"\"\"平均ベクトルを更新する．\"\"\"\n",
        "        idx = np.argsort(self.arf)  # idx[i]は評価値がi番目に良い解のインデックス\n",
        "        self.mean += np.dot(self.weights, (self.arx[idx] - self.mean))\n",
        "\n",
        "    def update_sigma(self):\n",
        "        \"\"\"ステップサイズを更新する．\"\"\"\n",
        "        self.sigma = self.sigma_coeff * np.linalg.norm(self.mean) / self.N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZhAk72BCO4oy"
      },
      "outputs": [],
      "source": [
        "def sphere(x):\n",
        "    \"\"\"Sphere関数．最適解は(0,...,0)\"\"\"\n",
        "    return np.dot(x, x) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3BHXcgiO4oz"
      },
      "outputs": [],
      "source": [
        "es = OptimalES(func=sphere,\n",
        "        init_mean=np.ones(10),\n",
        "        sigma_coeff=0.01,\n",
        "        nsample=10)\n",
        "\n",
        "maxiter = 5000\n",
        "fbest = np.zeros(maxiter) * np.nan\n",
        "fmean = np.zeros(maxiter) * np.nan\n",
        "sigmaN = np.zeros(maxiter) * np.nan\n",
        "for i in range(fbest.shape[0]):\n",
        "    es.sample()\n",
        "    es.evaluate()\n",
        "    es.update_mean()\n",
        "    es.update_sigma()\n",
        "    fbest[i] = es.arf.min()\n",
        "    fmean[i] = sphere(es.mean)\n",
        "    sigmaN[i] = es.sigma * es.N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ed_vmO8O4oz"
      },
      "outputs": [],
      "source": [
        "plt.semilogy(fbest, '-r', label='f(best)')\n",
        "plt.semilogy(fmean, '-b', label='f(mean)')\n",
        "plt.semilogy(sigmaN, '--g', label='sigma*N')\n",
        "plt.xlabel('no. of iterations', fontsize='large')\n",
        "plt.grid()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeGhkX7XO4o0"
      },
      "source": [
        "収束の速さ(傾き)を比較する．\n",
        "$$CR := -\\frac{N}{t}\\log_{10}\\frac{\\|X^{(t)}\\|}{\\|X^{(0)}\\|}$$\n",
        "$CR > 0$ ならば収束(高いほど速い)，$CR < 0$ならば発散"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "3ums0mXMO4o0"
      },
      "outputs": [],
      "source": [
        "for N in [10, 100, 1000]:\n",
        "    sigma_co = 2 ** np.arange(-6., 3., 0.2)\n",
        "    init_mean = np.ones(N)\n",
        "    maxiter = 1000\n",
        "    nsample = 10\n",
        "    cr = np.zeros(sigma_co.shape[0])\n",
        "    nseed = 20\n",
        "\n",
        "    for j in range(sigma_co.shape[0]):\n",
        "        sc = sigma_co[j]\n",
        "        for seed in np.arange(nseed):\n",
        "            np.random.seed(seed * 100)  # 確率的アルゴリズムなので，複数回同じ設定で試行し，平均をとる．\n",
        "\n",
        "            es = OptimalES(func=sphere,\n",
        "                          init_mean=init_mean,\n",
        "                          sigma_coeff=sc,\n",
        "                          nsample=nsample)\n",
        "\n",
        "            for i in range(maxiter):\n",
        "                es.sample()\n",
        "                es.evaluate()\n",
        "                es.update_mean()\n",
        "                es.update_sigma()\n",
        "\n",
        "            cr[j] += - (np.log10(np.linalg.norm(es.mean)) - np.log10(np.linalg.norm(init_mean))) / maxiter\n",
        "        cr[j] *= es.N / nseed\n",
        "        print(sc, cr[j])\n",
        "\n",
        "    # Dataを保存しておく\n",
        "    np.savetxt('CR_Sphere_N' + str(init_mean.shape[0]) + '_L' + str(nsample) + '.csv', np.vstack((sigma_co, cr)).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3vtAHGTO4o0"
      },
      "outputs": [],
      "source": [
        "data = np.loadtxt('CR_Sphere_N10_L10.csv')\n",
        "plt.semilogx(data[:, 0], data[:, 1], '+r', label='N=10')\n",
        "data = np.loadtxt('CR_Sphere_N100_L10.csv')\n",
        "plt.semilogx(data[:, 0], data[:, 1], '*b', label='N=100')\n",
        "data = np.loadtxt('CR_Sphere_N1000_L10.csv')\n",
        "plt.semilogx(data[:, 0], data[:, 1], 'xg', label='N=1000')\n",
        "plt.grid()\n",
        "plt.legend(loc='best')\n",
        "plt.ylabel('Convergence Rate')\n",
        "plt.xlabel('Sigma Coefficient')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBVfQVWJO4o1"
      },
      "source": [
        "## ステップサイズの適応"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRQHZOqgO4o1"
      },
      "source": [
        "一般に，\n",
        "* 目的関数は凸二次関数ではない．\n",
        "* （ブラックボックス最適化の設定では）勾配は計算できないから，ステップサイズを更新するために勾配を使うことはできない．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAFxipbTO4o1"
      },
      "source": [
        "### Cumulative Step-size Adaptation (CSA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C8U5YNhO4o1"
      },
      "source": [
        "#### アイディア:\n",
        "* 平均ベクトルが同じ方向に移動している => ステップサイズを大きくする\n",
        "* 平均ベクトルがランダムに移動 => ステップサイズを変化させない\n",
        "* 平均ベクトルが行ったり来たり => ステップサイズを小さくする\n",
        "\n",
        "直感的には理解しやすいであろう．同じ方向に移動し続けているような状況は，ステップサイズが小さすぎると考えられ，逆に行ったり来たりしている状況はステップサイズが大きすぎると考えられる．ただ，どこを境に大きすぎる，小さすぎる，と判断するかは，なかなか直感的に決めることが難しいであろう．CSAのアルゴリズム設計上で最も重要な部分は，「平均ベクトルの移動がランダムであるとき」をステップサイズを増加させるか減少させるかの基準として設けている点である．\n",
        "\n",
        "#### なぜランダムに移動している場合が基準なのか\n",
        "現在のステップサイズが大きすぎるか小さすぎるかを判断する基準として，平均ベクトルがランダムに移動している場合を考えている．これは次のような観察に基づく．\n",
        "\n",
        "1. もしもステップサイズが適切な大きさだったとすれば，１イテレーション前に進んだ平均ベクトルの移動方向と，次に進む移動方向は垂直となることが期待される．そうでない場合，１イテレーション前に進んだ方向に更に進むか，もしくは逆方向に戻ることになるからである．\n",
        "\n",
        "2. 上の議論とは無関係に，もしも連続する２イテレーションの平均ベクトルの移動が独立に期待値0の確率ベクトルで表されるのであれば，その内積の期待値は０である．すなわち，期待値の意味で垂直である．\n",
        "\n",
        "ランダムな場合には，平均ベクトルが垂直に移動を繰り返していると期待されるため，ランダムな移動を繰り返している状況を基準としているのである．\n",
        "\n",
        "#### 具体的な更新方法\n",
        "ここまでの話では，簡単のため共分散行列は$\\Sigma = \\sigma^2 I$であるような場合しか検討していないが，この先の一般化を考慮して，以下のアルゴリズムでは解候補を生成する正規分布は$\\mathcal{N}(m, \\Sigma)$に従っていることを想定する．このような一般の正規分布は，$x_{i} \\sim m + \\sqrt{\\Sigma} \\mathcal{N}(0, I)$ と生成される．ここで，$\\sqrt{\\Sigma}$は$\\Sigma = \\sqrt{\\Sigma} \\sqrt{\\Sigma}$ を満たす非負定値対称行列である．\n",
        "\n",
        "ステップサイズの更新は以下のように行われる：\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p_\\sigma &\\leftarrow (1 - c_\\sigma) p_\\sigma + \\sqrt{\\frac{c_\\sigma (2 - c_\\sigma)}{\\sum_{j=1}^{\\lambda} w_j^2} } \\sum_{i=1}^{\\lambda} w_i \\sqrt{\\Sigma}^{-1} (x_{i:\\lambda} - m)\n",
        "\\\\\n",
        "\\sigma &\\leftarrow \\sigma \\exp\\left( \\frac{c_\\sigma}{d_\\sigma} \\left( \\frac{\\|p_\\sigma\\|}{\\mathbb{E}[\\|\\mathcal{N}(0, I)\\|]} - 1\\right)\\right)\n",
        "\\end{aligned}\n",
        "$$\n",
        "なお，$x_{i:\\lambda}$は$\\lambda$個の解の中で$i$番目に目的関数値の良い解，$m$は更新前の（$x_i$生成時の）平均ベクトルを表す．\n",
        "$c_\\sigma$はcumulation factorと呼ばれ，\n",
        "$1/c_\\sigma$に比例したイテレーション分の平均ベクトル移動量を累積していると考えられる．また，\n",
        "$d_\\sigma$は減衰率（damping factor）と呼ばれ，急激な$\\sigma$の変化を防ぐために導入されている．\n",
        "\n",
        "#### 設計原理\n",
        "$p_\\sigma$ は進化パス（evolution path）と呼ばれ，平均ベクトルの移動量を累積していることが分かる．ステップサイズ$\\sigma$は進化パスの長さをもとに更新されるが，この長さが次元数$N$の標準正規分布のノルムの期待値$\\mathbb{E}[\\|\\mathcal{N}(0, I)\\|]$と比べて大きければステップサイズを大きく，小さければステップサイズを小さくしている．この点については理解しやすいであろう．\n",
        "\n",
        "ここでは，「平均ベクトルがランダムに移動している場合にはステップサイズを変化させない」という設計指針が，どのようにして実現されているのかを，進化パスの各要素を見ていきながら確認する．\n",
        "\n",
        "以下の議論では，目的関数の値が$x$によらずにランダムに与えられるような状況を想定する．このとき，解候補のランキングはランダムであるから，$x_{i:\\lambda}$は独立に正規分布$x_{i} \\sim \\mathcal{N}(m, \\Sigma)$に従う．このとき，平均ベクトルはランダムに移動することになり，上述のステップサイズを変化させない状況に対応することが分かる．\n",
        "\n",
        "まず，$\\sqrt{\\Sigma}^{-1} (x_{i:\\lambda} - m)$について考える．正規分布の性質より，$\\sqrt{\\Sigma}^{-1} (x_{i:\\lambda} - m) \\sim \\mathcal{N}(0, I)$となる．これは，$x_{i:\\lambda}$を平均ベクトルが0，共分散行列が$I$となるように標準化していることにほかならない．\n",
        "\n",
        "次に，$\\sqrt{\\frac{1}{\\sum_{j=1}^{\\lambda} w_j^2} }\\sum_{i=1}^{\\lambda} w_i \\sqrt{\\Sigma}^{-1} (x_{i:\\lambda} - m)$について考える．$\\sqrt{\\Sigma}^{-1} (x_{i:\\lambda} - m) \\sim \\mathcal{N}(0, I)$が独立であることから，正規分布の性質より，\n",
        "$$\\sqrt{\\frac{1}{\\sum_{j=1}^{\\lambda} w_j^2} }\\sum_{i=1}^{\\lambda} w_i \\sqrt{\\Sigma}^{-1} (x_{i:\\lambda} - m) \\sim \\sqrt{\\frac{1}{\\sum_{j=1}^{\\lambda} w_j^2} }\\mathcal{N}\\left( 0, \\sum_{i=1}^{\\lambda} w_i^2 I \\right)\n",
        "\\sim \\mathcal{N}\\left( 0, I \\right)\n",
        "$$\n",
        "となる．平均が$0$の独立な確率変数の平均をとると，その分分散が小さくなるため，これを$\\sqrt{\\frac{1}{\\sum_{j=1}^{\\lambda} w_j^2} }$により補正している，と考えられる．なお，仮に目的関数値の優れる領域が平均ベクトルからみて一方向に偏っている場合，選択された標準化解$\\sqrt{\\Sigma}^{-1} (x_{i:\\lambda} - m)$ は正規分布に従わず，平均ベクトルも$0$とはならない．そのような場合，この補正により現在検討している項の大きさが大きくなる点もポイントである．\n",
        "\n",
        "最後に，$(1 - c_\\sigma)$と$\\sqrt{c_\\sigma (2 - c_\\sigma)}$について考える．初期の$p_\\sigma$を$p_\\sigma^{(0)}$，$t$回更新後の進化パスを$p_\\sigma^{(t)}$と書けば，ランダムな目的関数のもとでの更新後の進化パスは\n",
        "$$\\begin{aligned}\n",
        "p_\\sigma^{(t)}\n",
        "&\\sim (1 - c_\\sigma) p_\\sigma^{(t-1)} + \\sqrt{c_\\sigma (2 - c_\\sigma)} \\mathcal{N}(0, I)\n",
        "\\\\\n",
        "&\\sim (1 - c_\\sigma) p_\\sigma^{(t-1)} +  \\mathcal{N}(0, (c_\\sigma (2 - c_\\sigma))I)\n",
        "\\\\\n",
        "&\\sim (1 - c_\\sigma)^t p_\\sigma^{(0)} +  \\mathcal{N}\\left(0, (c_\\sigma (2 - c_\\sigma))\\left(\\sum_{i=0}^{t-1} (1 - c_\\sigma)^{2i} \\right) I \\right)\n",
        "\\\\\n",
        "&\\sim (1 - c_\\sigma)^t p_\\sigma^{(0)} +  \\mathcal{N}\\left(0, (1 - (1 - c_\\sigma)^{2t}) I \\right)\n",
        "\\end{aligned}$$\n",
        "に従う．すなわち，進化パスはおおよそ（$t$について漸近的に）$\\mathcal{N}(0, I)$に従うことが分かる．\n",
        "\n",
        "以上より，ランダムな目的関数のもとでは，進化パスはおおよそ$\\mathcal{N}(0, I)$に従うことになる．このとき，CSAでの対数ステップサイズの更新の期待値は\n",
        "$$\\begin{aligned}\n",
        "\\log(\\sigma)\n",
        "&\\leftarrow \\log(\\sigma) + \\mathbb{E}\\left[\\frac{c_\\sigma}{d_\\sigma} \\left( \\frac{\\|p_\\sigma\\|}{\\mathbb{E}[\\|\\mathcal{N}(0, I)\\|]} - 1\\right) \\right]\n",
        "\\\\\n",
        "&\\leftarrow \\log(\\sigma) + \\frac{c_\\sigma}{d_\\sigma} \\left( \\frac{\\mathbb{E}\\left[\\|p_\\sigma\\| \\right]}{\\mathbb{E}[\\|\\mathcal{N}(0, I)\\|]} - 1\\right)\n",
        "\\\\\n",
        "&\\leftarrow \\log(\\sigma)\n",
        "\\end{aligned}\n",
        "$$\n",
        "となるため，対数ステップサイズは不偏となる．このことから，CSAの更新式は設計アイディアを反映したものであることが分かる．\n",
        "\n",
        "参考：ランダムな目的関数の場合，そこから得られる情報はない．その場合，パラメータは変更されるべきでない，という考えは自然であり，上のようなパラメータ更新の不偏性を考えるということは，アルゴリズム設計上で非常に大切なことである．"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 実装"
      ],
      "metadata": {
        "id": "y2BJxCF54_pW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JcJh6vMIO4o1"
      },
      "outputs": [],
      "source": [
        "class CSAES(object):\n",
        "    \"\"\"CSA Evolution Strategy\"\"\"\n",
        "\n",
        "    def __init__(self, func, init_mean, init_sigma, nsample):\n",
        "        \"\"\"コンストラクタ\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        func : callable\n",
        "            目的関数 (最小化)\n",
        "        init_mean : ndarray (1D)\n",
        "            初期平均ベクトル\n",
        "        init_sigma : float\n",
        "            初期ステップサイズ\n",
        "        nsample : int\n",
        "            サンプル数\n",
        "        \"\"\"\n",
        "        self.func = func\n",
        "        self.mean = init_mean\n",
        "        self.sigma = init_sigma\n",
        "        self.N = self.mean.shape[0]                     # 探索空間の次元数\n",
        "        self.arx = np.zeros((nsample, self.N)) * np.nan # 候補解\n",
        "        self.arf = np.zeros(nsample) * np.nan           # 候補解の評価値\n",
        "\n",
        "        self.weights = np.zeros(nsample)\n",
        "        self.weights[:nsample//4] = 1.0 / (nsample//4)  # 重み．総和が1\n",
        "\n",
        "        # For CSA\n",
        "        self.ps = np.zeros(self.N)\n",
        "        self.cs = 4.0 / (self.N + 4.0)\n",
        "        self.ds = 1.0 + self.cs\n",
        "        self.chiN = np.sqrt(self.N) * (1.0 - 1.0 / (4.0 * self.N) + 1.0 / (21.0 * self.N * self.N))\n",
        "        self.mueff = 1.0 / np.sum(self.weights**2)\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"候補解を生成する．\"\"\"\n",
        "        self.arx = self.mean + self.sigma * np.random.normal(size=self.arx.shape)\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"候補解を評価する．\"\"\"\n",
        "        for i in range(self.arf.shape[0]):\n",
        "            self.arf[i] = self.func(self.arx[i])\n",
        "\n",
        "    def update_mean(self):\n",
        "        \"\"\"平均ベクトルを更新する．\"\"\"\n",
        "        idx = np.argsort(self.arf)  # idx[i]は評価値がi番目に良い解のインデックス\n",
        "        self.mean += np.dot(self.weights, (self.arx[idx] - self.mean))\n",
        "\n",
        "    def update_sigma(self):\n",
        "        \"\"\"CSA\"\"\"\n",
        "        idx = np.argsort(self.arf)  # idx[i]は評価値がi番目に良い解のインデックス\n",
        "        # 進化パスの更新 (平均ベクトル移動量の蓄積)\n",
        "        self.ps = (1 - self.cs) * self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mueff) * np.dot(self.weights, (self.arx[idx] - self.mean)) / self.sigma\n",
        "        # 進化パスの長さが，ランダム関数の下での期待値よりも大きければステップサイズを大きくする．\n",
        "        self.sigma = self.sigma * np.exp(self.cs / self.ds * (np.linalg.norm(self.ps) / self.chiN - 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTRctYmfO4o2"
      },
      "outputs": [],
      "source": [
        "es = CSAES(func=sphere,\n",
        "           init_mean=np.ones(10),\n",
        "           init_sigma=1.,\n",
        "           nsample=10)\n",
        "\n",
        "maxiter = 200\n",
        "mean = np.zeros(maxiter) * np.nan\n",
        "sigmaN = np.zeros(maxiter) * np.nan\n",
        "for i in range(maxiter):\n",
        "    es.sample()\n",
        "    es.evaluate()\n",
        "    es.update_sigma()\n",
        "    es.update_mean()\n",
        "    mean[i] = sphere(es.mean)\n",
        "    sigmaN[i] = es.sigma * es.N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGjdYSosO4o2"
      },
      "outputs": [],
      "source": [
        "plt.semilogy(mean, '-b', label='f(mean)')\n",
        "plt.semilogy(sigmaN, '--g', label='sigma*N')\n",
        "plt.xlabel('no. of iterations', fontsize='large')\n",
        "plt.grid()\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKI07eDgO4o2"
      },
      "source": [
        "#### 最適ステップサイズとの比較"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbtoszvaO4o2"
      },
      "outputs": [],
      "source": [
        "# CSA\n",
        "plt.semilogy(sigmaN / mean, '-b', label='CSA')\n",
        "# Optimal\n",
        "data = np.loadtxt('CR_Sphere_N10_L10.csv')\n",
        "idx = np.argmax(data[:, 1])\n",
        "plt.semilogy(np.ones(mean.shape) * data[idx, 0], '-r', label='Opt')\n",
        "\n",
        "plt.title('sigma * N / ||M|| 10D-Sphere')\n",
        "plt.xlabel('no. of iterations', fontsize='large')\n",
        "plt.grid()\n",
        "plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "8fC5Sx5GO4o3"
      },
      "source": [
        "#### 確認事項\n",
        "* 初期ステップサイズが小さすぎる場合，定常なステップサイズを学習するまでに時間がかかる\n",
        "* 学習されるステップサイズが最適なものよりも大きい傾向にある"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 考察\n",
        "CSAの解説において，目的関数がランダムである場合を検討した．この場合，$x_{i:\\lambda}$がこれを生成する際に用いられた正規分布$\\mathcal{N}(m, \\Sigma)$に従うことを述べた．目的関数がランダムではない場合，当然，生成する際の分布とランキング計算後の解$x_{i:\\lambda}$の分布は異なる．仮に$x_{1:\\lambda}, \\dots, x_{\\lfloor \\lambda / 4 \\rfloor:\\lambda}$の分布が独立に$\\mathcal{N}(m^*, \\Sigma^*)$に従うと想定した場合，進化パスがどのような分布に従い，ステップサイズの更新がどのようになるのか，検討してみましょう．\n",
        "\n",
        "（なお，筆者は上記のような考察をすることで，CSAの問題点を指摘して改良した方法を学生時代に提案しています．Akimoto et al., Functionally Specialized CMA-ES: A Modification of CMA-ES based on the Specialization of the Functions of Covariance Matrix Adaptation and Step Size Adaptation, GECCO 2008）"
      ],
      "metadata": {
        "id": "0N_gMNBQTKMC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Uk7yULgO6rN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}